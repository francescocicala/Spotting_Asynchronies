{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 0\n",
    "\n",
    "data_directory = \"../DATASET/mode_\" + str(mode) + \"/downsampling/\"\n",
    "\n",
    "X_train = np.load(data_directory + \"X_train.npy\")\n",
    "y_train = np.load(data_directory + \"y_train.npy\")\n",
    "\n",
    "X_val = np.load(data_directory + \"X_val.npy\")\n",
    "y_val = np.load(data_directory + \"y_val.npy\")\n",
    "\n",
    "X_test = np.load(data_directory + \"X_test.npy\")\n",
    "y_test = np.load(data_directory + \"y_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2512, 250, 2), (1022, 250, 2))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D\n",
    "\n",
    "seq_length = 250\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(64, 10, strides=1, activation='relu', input_shape=(seq_length, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(64, 10, strides=1, activation='relu'))\n",
    "model.add(MaxPooling1D(4))\n",
    "model.add(Conv1D(128, 10, strides=1, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(128, 10, strides=1, activation='relu'))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2512 samples, validate on 640 samples\n",
      "Epoch 1/200\n",
      "2512/2512 [==============================] - 4s 1ms/step - loss: 0.3317 - acc: 0.8372 - val_loss: 0.2882 - val_acc: 0.8313\n",
      "Epoch 2/200\n",
      "2512/2512 [==============================] - 1s 302us/step - loss: 0.2712 - acc: 0.8754 - val_loss: 2.0776 - val_acc: 0.8000\n",
      "Epoch 3/200\n",
      "2512/2512 [==============================] - 1s 303us/step - loss: 0.2483 - acc: 0.8937 - val_loss: 1.4304 - val_acc: 0.7969\n",
      "Epoch 4/200\n",
      "2512/2512 [==============================] - 1s 323us/step - loss: 0.2340 - acc: 0.8985 - val_loss: 0.3469 - val_acc: 0.8172\n",
      "Epoch 5/200\n",
      "2512/2512 [==============================] - 1s 306us/step - loss: 0.2238 - acc: 0.9136 - val_loss: 0.6149 - val_acc: 0.7953\n",
      "Epoch 6/200\n",
      "2512/2512 [==============================] - 1s 301us/step - loss: 0.2166 - acc: 0.9096 - val_loss: 0.4266 - val_acc: 0.8172\n",
      "Epoch 7/200\n",
      "2512/2512 [==============================] - 1s 323us/step - loss: 0.2121 - acc: 0.9176 - val_loss: 0.2526 - val_acc: 0.8734\n",
      "Epoch 8/200\n",
      "2512/2512 [==============================] - 1s 323us/step - loss: 0.2064 - acc: 0.9176 - val_loss: 0.2147 - val_acc: 0.9250\n",
      "Epoch 9/200\n",
      "2512/2512 [==============================] - 1s 311us/step - loss: 0.2091 - acc: 0.9108 - val_loss: 0.7811 - val_acc: 0.7969\n",
      "Epoch 10/200\n",
      "2512/2512 [==============================] - 1s 295us/step - loss: 0.2133 - acc: 0.9120 - val_loss: 0.2085 - val_acc: 0.9234\n",
      "Epoch 11/200\n",
      "2512/2512 [==============================] - 1s 311us/step - loss: 0.2052 - acc: 0.9212 - val_loss: 0.2844 - val_acc: 0.8938\n",
      "Epoch 12/200\n",
      "2512/2512 [==============================] - 1s 323us/step - loss: 0.1966 - acc: 0.9279 - val_loss: 0.2023 - val_acc: 0.9219\n",
      "Epoch 13/200\n",
      "2512/2512 [==============================] - 1s 313us/step - loss: 0.1929 - acc: 0.9184 - val_loss: 0.2055 - val_acc: 0.9187\n",
      "Epoch 14/200\n",
      "2512/2512 [==============================] - 1s 326us/step - loss: 0.2042 - acc: 0.9240 - val_loss: 0.2303 - val_acc: 0.9234\n",
      "Epoch 15/200\n",
      "2512/2512 [==============================] - 1s 341us/step - loss: 0.1965 - acc: 0.9283 - val_loss: 0.2539 - val_acc: 0.9250\n",
      "Epoch 16/200\n",
      "2512/2512 [==============================] - 1s 326us/step - loss: 0.2000 - acc: 0.9220 - val_loss: 0.2101 - val_acc: 0.9172\n",
      "Epoch 17/200\n",
      "2512/2512 [==============================] - 1s 328us/step - loss: 0.2020 - acc: 0.9204 - val_loss: 0.7999 - val_acc: 0.7984\n",
      "Epoch 18/200\n",
      "2512/2512 [==============================] - 1s 336us/step - loss: 0.1979 - acc: 0.9220 - val_loss: 0.1882 - val_acc: 0.9156\n",
      "Epoch 19/200\n",
      "2512/2512 [==============================] - 1s 327us/step - loss: 0.1951 - acc: 0.9196 - val_loss: 0.1891 - val_acc: 0.9203\n",
      "Epoch 20/200\n",
      "2512/2512 [==============================] - 1s 349us/step - loss: 0.1932 - acc: 0.9212 - val_loss: 0.2328 - val_acc: 0.8953\n",
      "Epoch 21/200\n",
      "2512/2512 [==============================] - 1s 358us/step - loss: 0.1867 - acc: 0.9220 - val_loss: 0.2868 - val_acc: 0.8703\n",
      "Epoch 22/200\n",
      "2512/2512 [==============================] - 1s 347us/step - loss: 0.1871 - acc: 0.9228 - val_loss: 0.2522 - val_acc: 0.8969\n",
      "Epoch 23/200\n",
      "2512/2512 [==============================] - 1s 350us/step - loss: 0.1966 - acc: 0.9252 - val_loss: 0.2125 - val_acc: 0.9094\n",
      "Epoch 24/200\n",
      "2512/2512 [==============================] - 1s 352us/step - loss: 0.1872 - acc: 0.9299 - val_loss: 0.2260 - val_acc: 0.9000\n",
      "Epoch 25/200\n",
      "2512/2512 [==============================] - 1s 348us/step - loss: 0.1842 - acc: 0.9323 - val_loss: 0.1933 - val_acc: 0.9172\n",
      "Epoch 26/200\n",
      "2512/2512 [==============================] - 1s 354us/step - loss: 0.1825 - acc: 0.9355 - val_loss: 0.2361 - val_acc: 0.8922\n",
      "Epoch 27/200\n",
      "2512/2512 [==============================] - 1s 345us/step - loss: 0.1692 - acc: 0.9343 - val_loss: 0.1993 - val_acc: 0.9281\n",
      "Epoch 28/200\n",
      "2512/2512 [==============================] - 1s 343us/step - loss: 0.1768 - acc: 0.9303 - val_loss: 0.2378 - val_acc: 0.8969\n",
      "Epoch 29/200\n",
      "2512/2512 [==============================] - 1s 346us/step - loss: 0.1742 - acc: 0.9319 - val_loss: 0.2071 - val_acc: 0.9141\n",
      "Epoch 30/200\n",
      "2512/2512 [==============================] - 1s 348us/step - loss: 0.1648 - acc: 0.9459 - val_loss: 0.2418 - val_acc: 0.9141\n",
      "Epoch 31/200\n",
      "2512/2512 [==============================] - 1s 338us/step - loss: 0.1609 - acc: 0.9371 - val_loss: 0.2096 - val_acc: 0.9078\n",
      "Epoch 32/200\n",
      "2512/2512 [==============================] - 1s 336us/step - loss: 0.1649 - acc: 0.9379 - val_loss: 0.1697 - val_acc: 0.9203\n",
      "Epoch 33/200\n",
      "2512/2512 [==============================] - 1s 338us/step - loss: 0.1613 - acc: 0.9379 - val_loss: 0.1775 - val_acc: 0.9281\n",
      "Epoch 34/200\n",
      "2512/2512 [==============================] - 1s 342us/step - loss: 0.1581 - acc: 0.9443 - val_loss: 0.3278 - val_acc: 0.8812\n",
      "Epoch 35/200\n",
      "2512/2512 [==============================] - 1s 337us/step - loss: 0.1470 - acc: 0.9502 - val_loss: 0.2555 - val_acc: 0.9000\n",
      "Epoch 36/200\n",
      "2512/2512 [==============================] - 1s 337us/step - loss: 0.1509 - acc: 0.9490 - val_loss: 0.1866 - val_acc: 0.9422\n",
      "Epoch 37/200\n",
      "2512/2512 [==============================] - 1s 343us/step - loss: 0.2738 - acc: 0.9371 - val_loss: 0.2534 - val_acc: 0.9203\n",
      "Epoch 38/200\n",
      "2512/2512 [==============================] - 1s 343us/step - loss: 0.1652 - acc: 0.9411 - val_loss: 0.5019 - val_acc: 0.8516\n",
      "Epoch 39/200\n",
      "2512/2512 [==============================] - 1s 337us/step - loss: 0.1614 - acc: 0.9435 - val_loss: 0.3049 - val_acc: 0.9078\n",
      "Epoch 40/200\n",
      "2512/2512 [==============================] - 1s 336us/step - loss: 0.1382 - acc: 0.9506 - val_loss: 0.1824 - val_acc: 0.9375\n",
      "Epoch 41/200\n",
      "2512/2512 [==============================] - 1s 344us/step - loss: 0.1513 - acc: 0.9518 - val_loss: 0.2289 - val_acc: 0.8969\n",
      "Epoch 42/200\n",
      "2512/2512 [==============================] - 1s 346us/step - loss: 0.1413 - acc: 0.9514 - val_loss: 0.1839 - val_acc: 0.9187\n",
      "Epoch 43/200\n",
      "2512/2512 [==============================] - 1s 339us/step - loss: 0.1415 - acc: 0.9502 - val_loss: 0.1379 - val_acc: 0.9437\n",
      "Epoch 44/200\n",
      "2512/2512 [==============================] - 1s 337us/step - loss: 0.1432 - acc: 0.9490 - val_loss: 0.1483 - val_acc: 0.9484\n",
      "Epoch 45/200\n",
      "2512/2512 [==============================] - 1s 339us/step - loss: 0.1380 - acc: 0.9498 - val_loss: 0.1159 - val_acc: 0.9500\n",
      "Epoch 46/200\n",
      "2512/2512 [==============================] - 1s 339us/step - loss: 0.1440 - acc: 0.9494 - val_loss: 0.2133 - val_acc: 0.8906\n",
      "Epoch 47/200\n",
      "2512/2512 [==============================] - 1s 339us/step - loss: 0.1332 - acc: 0.9562 - val_loss: 0.1365 - val_acc: 0.9422\n",
      "Epoch 48/200\n",
      "2512/2512 [==============================] - 1s 346us/step - loss: 0.1370 - acc: 0.9546 - val_loss: 0.1283 - val_acc: 0.9437\n",
      "Epoch 49/200\n",
      "2512/2512 [==============================] - 1s 336us/step - loss: 0.1261 - acc: 0.9582 - val_loss: 0.1543 - val_acc: 0.9422\n",
      "Epoch 50/200\n",
      "2512/2512 [==============================] - 1s 339us/step - loss: 0.1477 - acc: 0.9530 - val_loss: 0.1934 - val_acc: 0.9344\n",
      "Epoch 51/200\n",
      "2512/2512 [==============================] - 1s 340us/step - loss: 0.1282 - acc: 0.9558 - val_loss: 0.1379 - val_acc: 0.9469\n",
      "Epoch 52/200\n",
      "2512/2512 [==============================] - 1s 339us/step - loss: 0.1420 - acc: 0.9534 - val_loss: 0.1288 - val_acc: 0.9469\n",
      "Epoch 53/200\n",
      "2512/2512 [==============================] - 1s 339us/step - loss: 0.1389 - acc: 0.9546 - val_loss: 0.1392 - val_acc: 0.9422\n",
      "Epoch 54/200\n",
      "2512/2512 [==============================] - 1s 341us/step - loss: 0.1250 - acc: 0.9602 - val_loss: 0.1320 - val_acc: 0.9500\n",
      "Epoch 55/200\n",
      "2512/2512 [==============================] - 1s 338us/step - loss: 0.1440 - acc: 0.9538 - val_loss: 0.1136 - val_acc: 0.9531\n",
      "Epoch 56/200\n",
      "2512/2512 [==============================] - 1s 336us/step - loss: 0.1362 - acc: 0.9542 - val_loss: 0.1958 - val_acc: 0.9391\n",
      "Epoch 57/200\n",
      "2512/2512 [==============================] - 1s 338us/step - loss: 0.1233 - acc: 0.9582 - val_loss: 0.1412 - val_acc: 0.9469\n",
      "Epoch 58/200\n",
      "2512/2512 [==============================] - 1s 338us/step - loss: 0.1296 - acc: 0.9546 - val_loss: 0.1920 - val_acc: 0.9203\n",
      "Epoch 59/200\n",
      "2512/2512 [==============================] - 1s 343us/step - loss: 0.1242 - acc: 0.9546 - val_loss: 0.2559 - val_acc: 0.9031\n",
      "Epoch 60/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2512/2512 [==============================] - 1s 343us/step - loss: 0.1313 - acc: 0.9602 - val_loss: 0.1462 - val_acc: 0.9469\n",
      "Epoch 61/200\n",
      "2512/2512 [==============================] - 1s 337us/step - loss: 0.1254 - acc: 0.9594 - val_loss: 0.1636 - val_acc: 0.9406\n",
      "Epoch 62/200\n",
      "2512/2512 [==============================] - 1s 335us/step - loss: 0.1254 - acc: 0.9590 - val_loss: 0.1377 - val_acc: 0.9500\n",
      "Epoch 63/200\n",
      "2512/2512 [==============================] - 1s 341us/step - loss: 0.1305 - acc: 0.9574 - val_loss: 0.1493 - val_acc: 0.9422\n",
      "Epoch 64/200\n",
      "2512/2512 [==============================] - 1s 335us/step - loss: 0.1209 - acc: 0.9582 - val_loss: 0.1411 - val_acc: 0.9563\n",
      "Epoch 65/200\n",
      "2512/2512 [==============================] - 1s 335us/step - loss: 0.1426 - acc: 0.9550 - val_loss: 0.1997 - val_acc: 0.9578\n",
      "Epoch 66/200\n",
      "2512/2512 [==============================] - 1s 345us/step - loss: 0.1338 - acc: 0.9590 - val_loss: 0.1412 - val_acc: 0.9609\n",
      "Epoch 67/200\n",
      "2512/2512 [==============================] - 1s 353us/step - loss: 0.1297 - acc: 0.9578 - val_loss: 0.2328 - val_acc: 0.9187\n",
      "Epoch 68/200\n",
      "2512/2512 [==============================] - 1s 339us/step - loss: 0.1322 - acc: 0.9586 - val_loss: 0.1485 - val_acc: 0.9516\n",
      "Epoch 69/200\n",
      "2512/2512 [==============================] - 1s 338us/step - loss: 0.1165 - acc: 0.9622 - val_loss: 0.1267 - val_acc: 0.9578\n",
      "Epoch 70/200\n",
      "2512/2512 [==============================] - 1s 337us/step - loss: 0.1255 - acc: 0.9630 - val_loss: 0.1525 - val_acc: 0.9469\n",
      "Epoch 71/200\n",
      "2512/2512 [==============================] - 1s 338us/step - loss: 0.1162 - acc: 0.9650 - val_loss: 0.1502 - val_acc: 0.9500\n",
      "Epoch 72/200\n",
      "2512/2512 [==============================] - 1s 339us/step - loss: 0.1295 - acc: 0.9570 - val_loss: 0.2614 - val_acc: 0.9125\n",
      "Epoch 73/200\n",
      "2512/2512 [==============================] - 1s 342us/step - loss: 0.1122 - acc: 0.9618 - val_loss: 0.1450 - val_acc: 0.9625\n",
      "Epoch 74/200\n",
      "2512/2512 [==============================] - 1s 338us/step - loss: 0.1215 - acc: 0.9630 - val_loss: 0.1414 - val_acc: 0.9484\n",
      "Epoch 75/200\n",
      "2512/2512 [==============================] - 1s 342us/step - loss: 0.1208 - acc: 0.9614 - val_loss: 0.1351 - val_acc: 0.9531\n",
      "Epoch 76/200\n",
      "2512/2512 [==============================] - 1s 340us/step - loss: 0.1242 - acc: 0.9602 - val_loss: 0.1544 - val_acc: 0.9531\n",
      "Epoch 77/200\n",
      "2512/2512 [==============================] - 1s 342us/step - loss: 0.1184 - acc: 0.9654 - val_loss: 0.2600 - val_acc: 0.9391\n",
      "Epoch 78/200\n",
      "2512/2512 [==============================] - 1s 339us/step - loss: 0.1150 - acc: 0.9606 - val_loss: 0.1893 - val_acc: 0.9531\n",
      "Epoch 79/200\n",
      "2512/2512 [==============================] - 1s 339us/step - loss: 0.1216 - acc: 0.9574 - val_loss: 0.1120 - val_acc: 0.9609\n",
      "Epoch 80/200\n",
      "2512/2512 [==============================] - 1s 338us/step - loss: 0.1166 - acc: 0.9614 - val_loss: 0.2619 - val_acc: 0.9094\n",
      "Epoch 81/200\n",
      "2512/2512 [==============================] - 1s 341us/step - loss: 0.1126 - acc: 0.9622 - val_loss: 0.1524 - val_acc: 0.9484\n",
      "Epoch 82/200\n",
      "2512/2512 [==============================] - 1s 348us/step - loss: 0.1142 - acc: 0.9662 - val_loss: 0.1367 - val_acc: 0.9500\n",
      "Epoch 83/200\n",
      "2512/2512 [==============================] - 1s 339us/step - loss: 0.1184 - acc: 0.9602 - val_loss: 0.1663 - val_acc: 0.9484\n",
      "Epoch 84/200\n",
      "2512/2512 [==============================] - 1s 340us/step - loss: 0.1195 - acc: 0.9646 - val_loss: 0.1368 - val_acc: 0.9563\n",
      "Epoch 85/200\n",
      "2512/2512 [==============================] - 1s 345us/step - loss: 0.1148 - acc: 0.9666 - val_loss: 0.1538 - val_acc: 0.9547\n",
      "Epoch 86/200\n",
      "2512/2512 [==============================] - 1s 361us/step - loss: 0.1138 - acc: 0.9654 - val_loss: 0.1270 - val_acc: 0.9656\n",
      "Epoch 87/200\n",
      "2512/2512 [==============================] - 1s 350us/step - loss: 0.1125 - acc: 0.9618 - val_loss: 0.2601 - val_acc: 0.9266\n",
      "Epoch 88/200\n",
      "2512/2512 [==============================] - 1s 337us/step - loss: 0.1179 - acc: 0.9686 - val_loss: 0.1230 - val_acc: 0.9578\n",
      "Epoch 89/200\n",
      "2512/2512 [==============================] - 1s 341us/step - loss: 0.1138 - acc: 0.9622 - val_loss: 0.1483 - val_acc: 0.9594\n",
      "Epoch 90/200\n",
      "2512/2512 [==============================] - 1s 338us/step - loss: 0.1151 - acc: 0.9654 - val_loss: 0.1628 - val_acc: 0.9563\n",
      "Epoch 91/200\n",
      "2512/2512 [==============================] - 1s 348us/step - loss: 0.1101 - acc: 0.9634 - val_loss: 0.1071 - val_acc: 0.9563\n",
      "Epoch 92/200\n",
      "2512/2512 [==============================] - 1s 325us/step - loss: 0.1246 - acc: 0.9598 - val_loss: 0.2003 - val_acc: 0.9516\n",
      "Epoch 93/200\n",
      "2512/2512 [==============================] - 1s 314us/step - loss: 0.1072 - acc: 0.9705 - val_loss: 0.1345 - val_acc: 0.9500\n",
      "Epoch 94/200\n",
      "2512/2512 [==============================] - 1s 312us/step - loss: 0.1131 - acc: 0.9654 - val_loss: 0.1364 - val_acc: 0.9594\n",
      "Epoch 95/200\n",
      "2512/2512 [==============================] - 1s 312us/step - loss: 0.1208 - acc: 0.9650 - val_loss: 0.1475 - val_acc: 0.9609\n",
      "Epoch 96/200\n",
      "2512/2512 [==============================] - 1s 310us/step - loss: 0.1083 - acc: 0.9606 - val_loss: 0.2420 - val_acc: 0.9344\n",
      "Epoch 97/200\n",
      "2512/2512 [==============================] - 1s 316us/step - loss: 0.1156 - acc: 0.9642 - val_loss: 0.1357 - val_acc: 0.9500\n",
      "Epoch 98/200\n",
      "2512/2512 [==============================] - 1s 313us/step - loss: 0.1077 - acc: 0.9674 - val_loss: 0.1385 - val_acc: 0.9594\n",
      "Epoch 99/200\n",
      "2512/2512 [==============================] - 1s 311us/step - loss: 0.1047 - acc: 0.9666 - val_loss: 0.1169 - val_acc: 0.9594\n",
      "Epoch 100/200\n",
      "2512/2512 [==============================] - 1s 310us/step - loss: 0.1052 - acc: 0.9689 - val_loss: 0.2646 - val_acc: 0.9156\n",
      "Epoch 101/200\n",
      "2512/2512 [==============================] - 1s 311us/step - loss: 0.1112 - acc: 0.9662 - val_loss: 0.2023 - val_acc: 0.9594\n",
      "Epoch 102/200\n",
      "2512/2512 [==============================] - 1s 313us/step - loss: 0.1179 - acc: 0.9622 - val_loss: 0.1651 - val_acc: 0.9359\n",
      "Epoch 103/200\n",
      "2512/2512 [==============================] - 1s 315us/step - loss: 0.1099 - acc: 0.9598 - val_loss: 0.2133 - val_acc: 0.9172\n",
      "Epoch 104/200\n",
      "2512/2512 [==============================] - 1s 311us/step - loss: 0.1098 - acc: 0.9634 - val_loss: 0.1678 - val_acc: 0.9594\n",
      "Epoch 105/200\n",
      "2512/2512 [==============================] - 1s 317us/step - loss: 0.1076 - acc: 0.9650 - val_loss: 0.1155 - val_acc: 0.9641\n",
      "Epoch 106/200\n",
      "2512/2512 [==============================] - 1s 316us/step - loss: 0.0973 - acc: 0.9701 - val_loss: 0.1408 - val_acc: 0.9563\n",
      "Epoch 107/200\n",
      "2512/2512 [==============================] - 1s 315us/step - loss: 0.1156 - acc: 0.9725 - val_loss: 0.1776 - val_acc: 0.9484\n",
      "Epoch 108/200\n",
      "2512/2512 [==============================] - 1s 311us/step - loss: 0.1025 - acc: 0.9693 - val_loss: 0.1304 - val_acc: 0.9516\n",
      "Epoch 109/200\n",
      "2512/2512 [==============================] - 1s 309us/step - loss: 0.1034 - acc: 0.9693 - val_loss: 0.1890 - val_acc: 0.9313\n",
      "Epoch 110/200\n",
      "2512/2512 [==============================] - 1s 313us/step - loss: 0.1087 - acc: 0.9686 - val_loss: 0.1387 - val_acc: 0.9563\n",
      "Epoch 111/200\n",
      "2512/2512 [==============================] - 1s 313us/step - loss: 0.1018 - acc: 0.9674 - val_loss: 0.1091 - val_acc: 0.9563\n",
      "Epoch 112/200\n",
      "2512/2512 [==============================] - 1s 311us/step - loss: 0.1068 - acc: 0.9654 - val_loss: 0.1538 - val_acc: 0.9484\n",
      "Epoch 113/200\n",
      "2512/2512 [==============================] - 1s 321us/step - loss: 0.1057 - acc: 0.9662 - val_loss: 0.1681 - val_acc: 0.9375\n",
      "Epoch 114/200\n",
      "2512/2512 [==============================] - 1s 332us/step - loss: 0.1051 - acc: 0.9689 - val_loss: 0.1450 - val_acc: 0.9547\n",
      "Epoch 115/200\n",
      "2512/2512 [==============================] - 1s 315us/step - loss: 0.1140 - acc: 0.9658 - val_loss: 0.1313 - val_acc: 0.9547\n",
      "Epoch 116/200\n",
      "2512/2512 [==============================] - 1s 310us/step - loss: 0.1011 - acc: 0.9646 - val_loss: 0.1834 - val_acc: 0.9563\n",
      "Epoch 117/200\n",
      "2512/2512 [==============================] - 1s 337us/step - loss: 0.1069 - acc: 0.9693 - val_loss: 0.1649 - val_acc: 0.9547\n",
      "Epoch 118/200\n",
      "2512/2512 [==============================] - 1s 342us/step - loss: 0.0980 - acc: 0.9666 - val_loss: 0.2401 - val_acc: 0.9297\n",
      "Epoch 119/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2512/2512 [==============================] - 1s 316us/step - loss: 0.1030 - acc: 0.9670 - val_loss: 0.1147 - val_acc: 0.9563\n",
      "Epoch 120/200\n",
      "2512/2512 [==============================] - 1s 331us/step - loss: 0.1116 - acc: 0.9654 - val_loss: 0.1571 - val_acc: 0.9484\n",
      "Epoch 121/200\n",
      "2512/2512 [==============================] - 1s 334us/step - loss: 0.0952 - acc: 0.9678 - val_loss: 0.1560 - val_acc: 0.9578\n",
      "Epoch 122/200\n",
      "2512/2512 [==============================] - 1s 341us/step - loss: 0.1058 - acc: 0.9666 - val_loss: 0.1219 - val_acc: 0.9594\n",
      "Epoch 123/200\n",
      "2512/2512 [==============================] - 1s 346us/step - loss: 0.0990 - acc: 0.9666 - val_loss: 0.1248 - val_acc: 0.9594\n",
      "Epoch 124/200\n",
      "2512/2512 [==============================] - 1s 337us/step - loss: 0.0991 - acc: 0.9674 - val_loss: 0.1963 - val_acc: 0.9422\n",
      "Epoch 125/200\n",
      "2512/2512 [==============================] - 1s 318us/step - loss: 0.1043 - acc: 0.9709 - val_loss: 0.1541 - val_acc: 0.9563\n",
      "Epoch 126/200\n",
      "2512/2512 [==============================] - 1s 311us/step - loss: 0.0914 - acc: 0.9697 - val_loss: 0.2752 - val_acc: 0.9531\n",
      "Epoch 127/200\n",
      "2512/2512 [==============================] - 1s 318us/step - loss: 0.1091 - acc: 0.9670 - val_loss: 0.1186 - val_acc: 0.9641\n",
      "Epoch 128/200\n",
      "2512/2512 [==============================] - 1s 310us/step - loss: 0.1009 - acc: 0.9697 - val_loss: 0.1714 - val_acc: 0.9453\n",
      "Epoch 129/200\n",
      "2512/2512 [==============================] - 1s 310us/step - loss: 0.1032 - acc: 0.9682 - val_loss: 0.1099 - val_acc: 0.9563\n",
      "Epoch 130/200\n",
      "2512/2512 [==============================] - 1s 309us/step - loss: 0.1073 - acc: 0.9678 - val_loss: 0.1235 - val_acc: 0.9516\n",
      "Epoch 131/200\n",
      "2512/2512 [==============================] - 1s 310us/step - loss: 0.0960 - acc: 0.9674 - val_loss: 0.1249 - val_acc: 0.9578\n",
      "Epoch 132/200\n",
      "2512/2512 [==============================] - 1s 310us/step - loss: 0.1007 - acc: 0.9733 - val_loss: 0.1199 - val_acc: 0.9516\n",
      "Epoch 133/200\n",
      "2512/2512 [==============================] - 1s 310us/step - loss: 0.1072 - acc: 0.9674 - val_loss: 0.1990 - val_acc: 0.9484\n",
      "Epoch 134/200\n",
      "2512/2512 [==============================] - 1s 311us/step - loss: 0.0943 - acc: 0.9709 - val_loss: 0.1859 - val_acc: 0.9594\n",
      "Epoch 135/200\n",
      "2512/2512 [==============================] - 1s 310us/step - loss: 0.1060 - acc: 0.9701 - val_loss: 0.2173 - val_acc: 0.9500\n",
      "Epoch 136/200\n",
      "2512/2512 [==============================] - 1s 313us/step - loss: 0.0992 - acc: 0.9709 - val_loss: 0.1490 - val_acc: 0.9578\n",
      "Epoch 137/200\n",
      "2512/2512 [==============================] - 1s 310us/step - loss: 0.0929 - acc: 0.9709 - val_loss: 0.1331 - val_acc: 0.9563\n",
      "Epoch 138/200\n",
      "2512/2512 [==============================] - 1s 317us/step - loss: 0.0851 - acc: 0.9745 - val_loss: 0.2393 - val_acc: 0.9609\n",
      "Epoch 139/200\n",
      "2512/2512 [==============================] - 1s 312us/step - loss: 0.1044 - acc: 0.9693 - val_loss: 0.1293 - val_acc: 0.9594\n",
      "Epoch 140/200\n",
      "2512/2512 [==============================] - 1s 311us/step - loss: 0.1010 - acc: 0.9725 - val_loss: 0.1467 - val_acc: 0.9578\n",
      "Epoch 141/200\n",
      "2512/2512 [==============================] - 1s 312us/step - loss: 0.0755 - acc: 0.9757 - val_loss: 0.2278 - val_acc: 0.9516\n",
      "Epoch 142/200\n",
      "2512/2512 [==============================] - 1s 310us/step - loss: 0.0916 - acc: 0.9725 - val_loss: 0.1920 - val_acc: 0.9437\n",
      "Epoch 143/200\n",
      "2512/2512 [==============================] - 1s 309us/step - loss: 0.0932 - acc: 0.9713 - val_loss: 0.1280 - val_acc: 0.9500\n",
      "Epoch 144/200\n",
      "2512/2512 [==============================] - 1s 313us/step - loss: 0.0990 - acc: 0.9686 - val_loss: 0.3993 - val_acc: 0.9281\n",
      "Epoch 145/200\n",
      "2512/2512 [==============================] - 1s 316us/step - loss: 0.0917 - acc: 0.9737 - val_loss: 0.1460 - val_acc: 0.9547\n",
      "Epoch 146/200\n",
      "2512/2512 [==============================] - 1s 313us/step - loss: 0.0938 - acc: 0.9745 - val_loss: 0.1292 - val_acc: 0.9547\n",
      "Epoch 147/200\n",
      "2512/2512 [==============================] - 1s 315us/step - loss: 0.1045 - acc: 0.9741 - val_loss: 0.1266 - val_acc: 0.9547\n",
      "Epoch 148/200\n",
      "2512/2512 [==============================] - 1s 315us/step - loss: 0.0860 - acc: 0.9709 - val_loss: 0.2502 - val_acc: 0.9375\n",
      "Epoch 149/200\n",
      "2512/2512 [==============================] - 1s 312us/step - loss: 0.1014 - acc: 0.9709 - val_loss: 0.1567 - val_acc: 0.9609\n",
      "Epoch 150/200\n",
      "2512/2512 [==============================] - 1s 311us/step - loss: 0.0866 - acc: 0.9713 - val_loss: 0.1258 - val_acc: 0.9656\n",
      "Epoch 151/200\n",
      "2512/2512 [==============================] - 1s 311us/step - loss: 0.1007 - acc: 0.9705 - val_loss: 0.1424 - val_acc: 0.9578\n",
      "Epoch 152/200\n",
      "2512/2512 [==============================] - 1s 311us/step - loss: 0.0807 - acc: 0.9753 - val_loss: 0.1785 - val_acc: 0.9594\n",
      "Epoch 153/200\n",
      "2512/2512 [==============================] - 1s 312us/step - loss: 0.0872 - acc: 0.9670 - val_loss: 0.1670 - val_acc: 0.9594\n",
      "Epoch 154/200\n",
      "2512/2512 [==============================] - 1s 314us/step - loss: 0.0863 - acc: 0.9753 - val_loss: 0.1681 - val_acc: 0.9625\n",
      "Epoch 155/200\n",
      "2512/2512 [==============================] - 1s 313us/step - loss: 0.0838 - acc: 0.9745 - val_loss: 0.1378 - val_acc: 0.9594\n",
      "Epoch 156/200\n",
      "2512/2512 [==============================] - 1s 312us/step - loss: 0.0953 - acc: 0.9729 - val_loss: 0.1282 - val_acc: 0.9547\n",
      "Epoch 157/200\n",
      "2512/2512 [==============================] - 1s 314us/step - loss: 0.0867 - acc: 0.9741 - val_loss: 0.2100 - val_acc: 0.9547\n",
      "Epoch 158/200\n",
      "2512/2512 [==============================] - 1s 310us/step - loss: 0.0770 - acc: 0.9761 - val_loss: 0.2831 - val_acc: 0.9594\n",
      "Epoch 159/200\n",
      "2512/2512 [==============================] - 1s 312us/step - loss: 0.0824 - acc: 0.9745 - val_loss: 0.1939 - val_acc: 0.9578\n",
      "Epoch 160/200\n",
      "2512/2512 [==============================] - 1s 312us/step - loss: 0.0810 - acc: 0.9773 - val_loss: 0.2233 - val_acc: 0.9453\n",
      "Epoch 161/200\n",
      "2512/2512 [==============================] - 1s 311us/step - loss: 0.0920 - acc: 0.9729 - val_loss: 0.1583 - val_acc: 0.9359\n",
      "Epoch 162/200\n",
      "2512/2512 [==============================] - 1s 312us/step - loss: 0.0863 - acc: 0.9717 - val_loss: 0.1779 - val_acc: 0.9547\n",
      "Epoch 163/200\n",
      "2512/2512 [==============================] - 1s 314us/step - loss: 0.0913 - acc: 0.9761 - val_loss: 0.1725 - val_acc: 0.9531\n",
      "Epoch 164/200\n",
      "2512/2512 [==============================] - 1s 316us/step - loss: 0.0879 - acc: 0.9753 - val_loss: 0.2150 - val_acc: 0.9563\n",
      "Epoch 165/200\n",
      "2512/2512 [==============================] - 1s 317us/step - loss: 0.1058 - acc: 0.9705 - val_loss: 0.1615 - val_acc: 0.9484\n",
      "Epoch 166/200\n",
      "2512/2512 [==============================] - 1s 316us/step - loss: 0.0900 - acc: 0.9729 - val_loss: 0.2878 - val_acc: 0.9391\n",
      "Epoch 167/200\n",
      "2512/2512 [==============================] - 1s 312us/step - loss: 0.0877 - acc: 0.9725 - val_loss: 0.3155 - val_acc: 0.9531\n",
      "Epoch 168/200\n",
      "2512/2512 [==============================] - 1s 313us/step - loss: 0.0900 - acc: 0.9717 - val_loss: 0.1267 - val_acc: 0.9531\n",
      "Epoch 169/200\n",
      "2512/2512 [==============================] - 1s 315us/step - loss: 0.0890 - acc: 0.9737 - val_loss: 0.1282 - val_acc: 0.9609\n",
      "Epoch 170/200\n",
      "2512/2512 [==============================] - 1s 336us/step - loss: 0.0869 - acc: 0.9749 - val_loss: 0.1325 - val_acc: 0.9703\n",
      "Epoch 171/200\n",
      "2512/2512 [==============================] - 1s 342us/step - loss: 0.0857 - acc: 0.9713 - val_loss: 0.2173 - val_acc: 0.9453\n",
      "Epoch 172/200\n",
      "2512/2512 [==============================] - 1s 300us/step - loss: 0.0912 - acc: 0.9777 - val_loss: 0.2052 - val_acc: 0.9625\n",
      "Epoch 173/200\n",
      "2512/2512 [==============================] - 1s 299us/step - loss: 0.0817 - acc: 0.9773 - val_loss: 0.1508 - val_acc: 0.9594\n",
      "Epoch 174/200\n",
      "2512/2512 [==============================] - 1s 330us/step - loss: 0.0759 - acc: 0.9777 - val_loss: 0.1421 - val_acc: 0.9484\n",
      "Epoch 175/200\n",
      "2512/2512 [==============================] - 1s 332us/step - loss: 0.0845 - acc: 0.9721 - val_loss: 0.1985 - val_acc: 0.9437\n",
      "Epoch 176/200\n",
      "2512/2512 [==============================] - 1s 353us/step - loss: 0.0809 - acc: 0.9729 - val_loss: 0.1864 - val_acc: 0.9641\n",
      "Epoch 177/200\n",
      "2512/2512 [==============================] - 1s 344us/step - loss: 0.0758 - acc: 0.9737 - val_loss: 0.3538 - val_acc: 0.9062\n",
      "Epoch 178/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2512/2512 [==============================] - 1s 344us/step - loss: 0.0828 - acc: 0.9765 - val_loss: 0.2025 - val_acc: 0.9547\n",
      "Epoch 179/200\n",
      "2512/2512 [==============================] - 1s 339us/step - loss: 0.1048 - acc: 0.9737 - val_loss: 0.1295 - val_acc: 0.9578\n",
      "Epoch 180/200\n",
      "2512/2512 [==============================] - 1s 315us/step - loss: 0.0690 - acc: 0.9761 - val_loss: 0.2133 - val_acc: 0.9531\n",
      "Epoch 181/200\n",
      "2512/2512 [==============================] - 1s 317us/step - loss: 0.0842 - acc: 0.9765 - val_loss: 0.1203 - val_acc: 0.9531\n",
      "Epoch 182/200\n",
      "2512/2512 [==============================] - 1s 313us/step - loss: 0.0736 - acc: 0.9769 - val_loss: 0.1747 - val_acc: 0.9641\n",
      "Epoch 183/200\n",
      "2512/2512 [==============================] - 1s 311us/step - loss: 0.1007 - acc: 0.9773 - val_loss: 0.1280 - val_acc: 0.9625\n",
      "Epoch 184/200\n",
      "2512/2512 [==============================] - 1s 311us/step - loss: 0.0889 - acc: 0.9773 - val_loss: 0.2799 - val_acc: 0.9437\n",
      "Epoch 185/200\n",
      "2512/2512 [==============================] - 1s 328us/step - loss: 0.0840 - acc: 0.9749 - val_loss: 0.3286 - val_acc: 0.9516\n",
      "Epoch 186/200\n",
      "2512/2512 [==============================] - 1s 318us/step - loss: 0.0787 - acc: 0.9789 - val_loss: 0.1566 - val_acc: 0.9578\n",
      "Epoch 187/200\n",
      "2512/2512 [==============================] - 1s 316us/step - loss: 0.0705 - acc: 0.9785 - val_loss: 0.1730 - val_acc: 0.9625\n",
      "Epoch 188/200\n",
      "2512/2512 [==============================] - 1s 311us/step - loss: 0.0665 - acc: 0.9781 - val_loss: 0.1430 - val_acc: 0.9563\n",
      "Epoch 189/200\n",
      "2512/2512 [==============================] - 1s 312us/step - loss: 0.0754 - acc: 0.9773 - val_loss: 0.1917 - val_acc: 0.9500\n",
      "Epoch 190/200\n",
      "2512/2512 [==============================] - 1s 312us/step - loss: 0.0802 - acc: 0.9757 - val_loss: 0.2925 - val_acc: 0.9578\n",
      "Epoch 191/200\n",
      "2512/2512 [==============================] - 1s 313us/step - loss: 0.0760 - acc: 0.9777 - val_loss: 0.2307 - val_acc: 0.9500\n",
      "Epoch 192/200\n",
      "2512/2512 [==============================] - 1s 313us/step - loss: 0.0701 - acc: 0.9769 - val_loss: 0.3816 - val_acc: 0.9281\n",
      "Epoch 193/200\n",
      "2512/2512 [==============================] - 1s 311us/step - loss: 0.0828 - acc: 0.9789 - val_loss: 0.1557 - val_acc: 0.9563\n",
      "Epoch 194/200\n",
      "2512/2512 [==============================] - 1s 312us/step - loss: 0.0857 - acc: 0.9749 - val_loss: 0.2718 - val_acc: 0.9516\n",
      "Epoch 195/200\n",
      "2512/2512 [==============================] - 1s 312us/step - loss: 0.0677 - acc: 0.9821 - val_loss: 0.2888 - val_acc: 0.9516\n",
      "Epoch 196/200\n",
      "2512/2512 [==============================] - 1s 311us/step - loss: 0.0872 - acc: 0.9753 - val_loss: 0.1657 - val_acc: 0.9641\n",
      "Epoch 197/200\n",
      "2512/2512 [==============================] - 1s 312us/step - loss: 0.0708 - acc: 0.9817 - val_loss: 0.2677 - val_acc: 0.9500\n",
      "Epoch 198/200\n",
      "2512/2512 [==============================] - 1s 311us/step - loss: 0.0628 - acc: 0.9801 - val_loss: 0.2174 - val_acc: 0.9594\n",
      "Epoch 199/200\n",
      "2512/2512 [==============================] - 1s 312us/step - loss: 0.0878 - acc: 0.9761 - val_loss: 0.1127 - val_acc: 0.9656\n",
      "Epoch 200/200\n",
      "2512/2512 [==============================] - 1s 311us/step - loss: 0.0709 - acc: 0.9825 - val_loss: 0.3108 - val_acc: 0.9484\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=32, epochs=200, validation_data=(X_val, y_val), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640/640 [==============================] - 0s 140us/step\n",
      "Validation loss: 0.3107555259069727\n",
      "Validation accuracy: 0.9484375\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_val, y_val, verbose=1, batch_size=16)\n",
    "print('Validation loss:', score[0])\n",
    "print('Validation accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzsnXd4XMW5/z+vuizJ6q6SLdvYxt2WZYOpdgBjh04I2HQS4iSk3IRfkktyc0NCGimXEBKSAAkthA6mhU5MMRhwxb1XWbKtZvW2u/P7Y87RHkkraWV7JZf38zz77J4+u3vOfOctMyPGGBRFURSlK6J6uwCKoijKsYEKhqIoihIWKhiKoihKWKhgKIqiKGGhgqEoiqKEhQqGoiiKEhYqGIpyGIhInogYEYkJY98bRWTx4Z5HUXoLFQzlhEFEdopIk4hktVm/yqms83qnZIpybKCCoZxo7ADmuwsiMgFI7L3iKMqxgwqGcqLxT+B6z/INwKPeHUQkVUQeFZESEdklIj8WkShnW7SI/F5ESkVkO3BBiGP/ISLFIrJXRH4hItHdLaSIDBKRl0SkXES2ishXPNumi8gyEakSkf0icpezPkFEHhORMhE5KCJLRaR/d6+tKB2hgqGcaHwM9BWRMU5FfhXwWJt9/gSkAsOBs7ECc5Oz7SvAhcAUoAC4os2xjwA+4CRnn9nAzYdQzieAQmCQc41ficg5zrY/An80xvQFRgBPO+tvcMqdC2QCXwPqD+HaihISFQzlRMS1Ms4DNgJ73Q0eEfmhMabaGLMT+D/gOmeXK4G7jTF7jDHlwK89x/YH5gLfMcbUGmMOAH8A5nWncCKSC5wB/LcxpsEYswr4u6cMzcBJIpJljKkxxnzsWZ8JnGSM8RtjlhtjqrpzbUXpDBUM5UTkn8DVwI20cUcBWUAcsMuzbhcw2Pk8CNjTZpvLUCAWKHZcQgeB+4B+3SzfIKDcGFPdQRm+DIwCNjpupws93+sN4EkRKRKR34pIbDevrSgdooKhnHAYY3Zhg9+fB55vs7kU21If6lk3hKAVUox1+Xi3uewBGoEsY0ya8+prjBnXzSIWARkikhKqDMaYLcaY+Vgh+g3wrIgkGWOajTE/M8aMBU7Dus6uR1GOECoYyonKl4HPGWNqvSuNMX5sTOCXIpIiIkOBWwnGOZ4Gvi0iOSKSDtzmObYYeBP4PxHpKyJRIjJCRM7uTsGMMXuAj4BfO4HsiU55/wUgIteKSLYxJgAcdA7zi8gsEZnguNWqsMLn7861FaUzVDCUExJjzDZjzLIONn8LqAW2A4uBx4EHnW0PYN0+nwEraG+hXI91aa0HKoBngYGHUMT5QB7W2lgI3G6MecvZNgdYJyI12AD4PGNMAzDAuV4VsAF4j/YBfUU5ZEQnUFIURVHCQS0MRVEUJSxUMBRFUZSwUMFQFEVRwkIFQ1EURQmL42oo5aysLJOXl9fbxVAURTlmWL58eakxJjucfY8rwcjLy2PZso4yJRVFUZS2iMiurveyqEtKURRFCQsVDEVRFCUsVDAURVGUsDiuYhihaG5uprCwkIaGht4uynFDQkICOTk5xMbqQKiKciJx3AtGYWEhKSkp5OXlISK9XZxjHmMMZWVlFBYWMmzYsN4ujqIoPchx75JqaGggMzNTxeIIISJkZmaqxaYoJyDHvWAAKhZHGP09FeXE5IQQjLDw+6C+ordLoSiKctSiguHSUAEVO61wHCHKysqYPHkykydPZsCAAQwePLhluampKaxz3HTTTWzatOmIlUlRFOVQOe6D3mHTMi9I4IidMjMzk1WrVgHw05/+lOTkZL73ve+1uazBGENUVGjtfuihh45YeRRFUQ4HtTBacASjByaU2rp1K+PHj+drX/sa+fn5FBcXs2DBAgoKChg3bhx33HFHy75nnHEGq1atwufzkZaWxm233cakSZOYMWMGBw4ciHhZFUVRXE4oC+NnL69jfVFV6I3+JvuKXQYSvo6OHdSX2y8a1+2yrF+/noceeoi//e1vANx5551kZGTg8/mYNWsWV1xxBWPHjm11TGVlJWeffTZ33nknt956Kw8++CC33XZbqNMriqIccdTC6CVGjBjBtGnTWpafeOIJ8vPzyc/PZ8OGDaxfv77dMYmJicydOxeAqVOnsnPnzp4qrqIoSuQsDBHJBR7FTkwfAO43xvyxzT6CncT+80AdcKMxZoWz7Qbgx86uvzDGPHK4ZerUEqjeB9XFkDUa4voc7qW6JCkpqeXzli1b+OMf/8inn35KWloa1157bch+DnFxcS2fo6Oj8fmOXIBeURSlKyJpYfiA/2eMGQOcCnxDRMa22WcuMNJ5LQD+CiAiGcDtwCnAdOB2EUmPYFk9RD6G0ZaqqipSUlLo27cvxcXFvPHGGz1eBkVRlK6ImIVhjCkGip3P1SKyARgMeH0tlwCPGmMM8LGIpInIQGAm8JYxphxARN4C5gBPRKq8waD3kcuSCpf8/HzGjh3L+PHjGT58OKeffnqPl0FRFKUrxPRAVpCI5AHvA+ONMVWe9a8AdxpjFjvL7wD/jRWMBGPML5z1/wvUG2N+H+LcC7DWCUOGDJm6a1fruUA2bNjAmDFjui5kVTHU7IOMEZDQt/tf8gQj7N9VUZSjGhFZbowpCGffiAe9RSQZeA74jlcs3M0hDjGdrG+/0pj7jTEFxpiC7OywZhnsgp53SSmKohwLRFQwRCQWKxb/MsY8H2KXQiDXs5wDFHWyPoL0XD8MRVGUY5GICYaTAfUPYIMx5q4OdnsJuF4spwKVTuzjDWC2iKQ7we7ZzrrI0wsxDEVRlGOBSHbcOx24DlgjIqucdT8ChgAYY/4GvIpNqd2KTau9ydlWLiI/B5Y6x93hBsAjh2nzriiKoniJZJbUYkLHIrz7GOAbHWx7EHgwAkXroDAtF+6xSyqKohxLaE/vdqhgKIqihEIFo4XIBL1nzpzZriPe3XffzS233NLhMcnJyQAUFRVxxRVXdHjeZcuWdXrtu+++m7q6upblz3/+8xw8eDDcoiuKorRCBaMtR1gw5s+fz5NPPtlq3ZNPPsn8+fO7PHbQoEE8++yzh3zttoLx6quvkpaWdsjnUxTlxEYFw8VEJuh9xRVX8Morr9DY2AjAzp07KSoqYvLkyZxzzjnk5+czYcIEXnzxxXbH7ty5k/HjxwNQX1/PvHnzmDhxIldddRX19fUt+339619vGRr99ttvB+Cee+6hqKiIWbNmMWvWLADy8vIoLS0F4K677mL8+PGMHz+eu+++u+V6Y8aM4Stf+Qrjxo1j9uzZra6jKMqJzQk1vDmv3Qb71oTe5muAQDNEx0F0fPjnHDAB5t7Z4ebMzEymT5/O66+/ziWXXMKTTz7JVVddRWJiIgsXLqRv376UlpZy6qmncvHFF3c4X/Zf//pX+vTpw+rVq1m9ejX5+fkt2375y1+SkZGB3+/nnHPOYfXq1Xz729/mrrvuYtGiRWRlZbU61/Lly3nooYf45JNPMMZwyimncPbZZ5Oens6WLVt44okneOCBB7jyyit57rnnuPbaa8P/PRRFOW5RC6MH8LqlXHeUMYYf/ehHTJw4kXPPPZe9e/eyf//+Ds/x/vvvt1TcEydOZOLEiS3bnn76afLz85kyZQrr1q0LOTS6l8WLF3PZZZeRlJREcnIyl19+OR988AEAw4YNY/LkyYAOoa4oSmtOLAujE0uAg7uhrgySsiE154he9tJLL+XWW29lxYoV1NfXk5+fz8MPP0xJSQnLly8nNjaWvLy8kEOaewllfezYsYPf//73LF26lPT0dG688cYuz9PZ+GHx8UHrKjo6Wl1SiqK0oBZGC5EbGiQ5OZmZM2fypS99qSXYXVlZSb9+/YiNjWXRokW0HTSxLWeddRb/+te/AFi7di2rV68G7NDoSUlJpKamsn//fl577bWWY1JSUqiurg55rhdeeIG6ujpqa2tZuHAhZ5555pH6uoqiHKecWBZGZ5h2H44o8+fP5/LLL29xTV1zzTVcdNFFFBQUMHnyZE4++eROj//617/OTTfdxMSJE5k8eTLTp08HYNKkSUyZMoVx48a1Gxp9wYIFzJ07l4EDB7Jo0aKW9fn5+dx4440t57j55puZMmWKup8URemUHhnevKcoKCgwbfsmhD0Md8UuqC+HxAxIHxqhEh4/6PDminJ8cFQNb37s0HsTKCmKohwLqGC4RNglpSiKcqxzQghGeG43nQ8jXI4nN6aiKOFz3AtGQkICZWVl4VdyWhl2ijGGsrIyEhISersoiqL0MMd9llROTg6FhYWUlJR0vmNtKTTXQUwVlDT3TOGOURISEsjJObJ9VRRFOfqJmGCIyIPAhcABY8z4ENu/D1zjKccYINuZPGknUA34AV+4EfxQxMbGMmzYsK53fPIa2PgK5EyDm98+1MspiqIct0TSJfUwMKejjcaY3xljJhtjJgM/BN5rM6veLGf7IYtFt3Czo/xNPXI5RVGUY42ICYYx5n0g3GlV5wNPRKosYdEiGOqOUhRFCUWvB71FpA/WEnnOs9oAb4rIchFZ0MXxC0RkmYgs6zJO0RkBv31XC0NRFCUkvS4YwEXAh23cUacbY/KBucA3ROSsjg42xtxvjCkwxhRkZ2cfeinUJaUoitIpR4NgzKONO8oYU+S8HwAWAtMjXgpXMHwqGIqiKKHoVcEQkVTgbOBFz7okEUlxPwOzgbURL4xaGIqiKJ0SybTaJ4CZQJaIFAK3A7EAxpi/ObtdBrxpjKn1HNofWOjM/RADPG6MeT1S5WxBg96KoiidEjHBMMbMD2Ofh7Hpt95124FJkSlVZ4VRC0NRFKUzjoYYxtGBVzB0eBBFUZR2qGC4tAxrboIptoqiKEoLKhguXpHwN/ZeORRFUY5SVDBcvBMnaRxDURSlHSoYLq0EQzOlFEVR2qKC4aIWhqIoSqeoYLioYCiKonSKCoaLuqQURVE6RQXDxQQgyunHqBaGoihKO1QwXEwAYpx5qnUAQkVRlHaoYLiYAMTE289qYSiKorRDBcMl4A9aGCoYiqIo7VDBcGllYWjQW1EUpS0qGC7GQEyi/awWhqIoSjtUMFw0hqEoitIpKhguxg+xamEoiqJ0RMQEQ0QeFJEDIhJyelURmSkilSKyynn9xLNtjohsEpGtInJbpMrYCrUwFEVROiWSFsbDwJwu9vnAGDPZed0BICLRwL3AXGAsMF9ExkawnBYT0BiGoihKJ0RMMIwx7wPlh3DodGCrMWa7MaYJeBK45IgWLhSaJaUoitIpvR3DmCEin4nIayIyzlk3GNjj2afQWRcSEVkgIstEZFlJScmhl0T7YSiKonRKbwrGCmCoMWYS8CfgBWe9hNi3w0m2jTH3G2MKjDEF2dnZh14aYzSGoSiK0gm9JhjGmCpjTI3z+VUgVkSysBZFrmfXHKAo8gXSsaQURVE6o9cEQ0QGiIg4n6c7ZSkDlgIjRWSYiMQB84CXIl4gE4CoaDtirVoYiqIo7YiJ1IlF5AlgJpAlIoXA7UAsgDHmb8AVwNdFxAfUA/OMMQbwicg3gTeAaOBBY8y6SJWzBeMHiYLoeBUMRVGUEERMMIwx87vY/mfgzx1sexV4NRLl6rhAAUcwYjVLSlEUJQS9nSV19OC6pKLjwN/Y26VRFEU56lDBcHEtjKgYm2KrKIqitEIFw0UFQ1EUpVNUMAACAfsuURAVBQFf75ZHURTlKEQFA6x1AR4LQwVDURSlLSoY0F4wjLqkFEVR2qKCASEsDBUMRVGUtqhgQNCikCj7UpeUoihKO1QwQC0MRVGUMFDBgKBguGNJqYWhKIrSDhUMaGNhRKtgKIqihEAFA9r0w4gJCoiiKIrSggoGqIWhKIoSBioY0FowRAVDURQlFCoYoFlSiqIoYRAxwRCRB0XkgIis7WD7NSKy2nl9JCKTPNt2isgaEVklIssiVcYWvP0wVDAURVFCEkkL42FgTifbdwBnG2MmAj8H7m+zfZYxZrIxpiBC5QtidPBBRVGUrojkjHvvi0heJ9s/8ix+DOREqixd0rYfho4lpSiK0o6jJYbxZeA1z7IB3hSR5SKyoLMDRWSBiCwTkWUlJSWHdnUdrVZRFKVLImZhhIuIzMIKxhme1acbY4pEpB/wlohsNMa8H+p4Y8z9OO6sgoICc0iFMM5hmiWlKIrSIb1qYYjIRODvwCXGmDJ3vTGmyHk/ACwEpke0IIG2QW/tuKcoitKWXhMMERkCPA9cZ4zZ7FmfJCIp7mdgNhAy0+qIoR33FEVRuiRiLikReQKYCWSJSCFwOxALYIz5G/ATIBP4i4gA+JyMqP7AQmddDPC4Meb1SJUT0BiGoihKGEQyS2p+F9tvBm4OsX47MKn9ERGkrYWhWVKKoijtOFqypHoX7binKIrSJSoYoDEMRVGUMFDBgNYd9yRaLQxFUZQQqGBA634YGvRWFEUJSViCISIjRCTe+TxTRL4tImmRLVoP0tIPQ4JDg5hD6wOoKIpyvBKuhfEc4BeRk4B/AMOAxyNWqp6mbQwD1C2lKIrShnAFI2CM8QGXAXcbY74LDIxcsXqYFsGIDgqGptYqiqK0IlzBaBaR+cANwCvOutjIFKkXaNtxDzSOoSiK0oZwBeMmYAbwS2PMDhEZBjwWuWL1MN5+GOK6pFQwFEVRvITV09sYsx74NoCIpAMpxpg7I1mwHiWkhaEuKUVRFC/hZkm9KyJ9RSQD+Ax4SETuimzRepBWEyhp0FtRFCUU4bqkUo0xVcDlwEPGmKnAuZErVg/Tqh+GuqQURVFCEa5gxIjIQOBKgkHv44cWl5QEXVKaJaUoitKKcAXjDuANYJsxZqmIDAe2RK5YPUzbCZRALQxFUZQ2hBv0fgZ4xrO8HfhCpArV47Tqh6FBb0VRlFCEG/TOEZGFInJARPaLyHMikhPpwvUY3iwpcX4SFQxFUZRWhOuSegh4CRgEDAZedtZ1iog86IhMyClWxXKPiGwVkdUiku/ZdoOIbHFeN4RZzkNDO+4piqJ0SbiCkW2MecgY43NeDwPZYRz3MDCnk+1zgZHOawHwVwAnffd24BRgOnC70/8jMrSdQAlUMBRFUdoQrmCUisi1IhLtvK4Fyro6yBjzPlDeyS6XAI8ay8dAmpONdT7wljGm3BhTAbxF58JzeIRKq9UsKUVRlFaEKxhfwqbU7gOKgSuww4UcLoOBPZ7lQmddR+vbISILRGSZiCwrKSk5tFK06rinQW9FUZRQhCUYxpjdxpiLjTHZxph+xphLsZ34DhcJdblO1ocq2/3GmAJjTEF2djheslAn8fbD0I57iqIooTicGfduPQLXLwRyPcs5QFEn6yNDINTgg2phKIqieDkcwQhlBXSXl4DrnWypU4FKY0wxtpPgbBFJd4Lds511kUGzpBRFUbokrI57HdDlHKYi8gQwE8gSkUJs5lMsgDHmb8CrwOeBrUAdTlzEGFMuIj8HljqnusMY01nw/PAI2XFPBUNRFMVLp4IhItWEFgYBErs6uTFmfhfbDfCNDrY9CDzY1TWOCKGmaHXXKYqiKEAXgmGMSempgvQqIef0VgtDURTFy+HEMI4fNIahKIrSJSoY0LofhmZJKYqihEQFA0LPh6EWhqIoSitUMKCDGIZaGIqiKF5UMCD0BEo6lpSiKEorVDCgTT8MzZJSFEUJhQoGaJaUoihKGKhgQAeCoS4pRVEULyoYoFO0KoqihIEKBqhLSlEUJQxUMMDTcU8FQ1EUpSNUMMAKhuuKisQUrYEANNUdufMpiqL0AioYYOMVLYIRgaD3yn/CHydqXERRlGMaFQxobWG0BL07cUnVHICq4vDPX7kHakvA13joZVQURellIioYIjJHRDaJyFYRuS3E9j+IyCrntVlEDnq2+T3bXopkOa1gRLsXtp87swZe+S688LXwz+8Khb/p0MuoKIrSyxzOjHudIiLRwL3Aedg5upeKyEvGmPXuPsaY73r2/xYwxXOKemPM5EiVrxVeCwOsW6ozC6OuHJqqwz+/KxQqGIqiHMNE0sKYDmw1xmw3xjQBTwKXdLL/fOCJCJanY4zpnmD4G8HXjcpfBUNRlOOASArGYGCPZ7nQWdcOERkKDAP+41mdICLLRORjEbm0o4uIyAJnv2UlJSWHVlLjbyMY0Z1P0eprsqIRLq64aAxDUZRjmEgKhoRYF2p+cIB5wLPGtMplHWKMKQCuBu4WkRGhDjTG3G+MKTDGFGRnZx9aSU3A9sFwiYru2sLwN4d/fldcunOMoijKUUYkBaMQyPUs5wBFHew7jzbuKGNMkfO+HXiX1vGNI0t3Yxi+xu5ZCy1Bb7UwFEU5domkYCwFRorIMBGJw4pCu2wnERkNpANLPOvSRSTe+ZwFnA6sb3vsESOkYHSSJeVv6l48oiWGoRaGoijHLhHLkjLG+ETkm8AbQDTwoDFmnYjcASwzxrjiMR940hjjdVeNAe4TkQBW1O70ZlcdcQJtYhhdpdV218LwawxDUZRjn4gJBoAx5lXg1TbrftJm+achjvsImBDJsrW+oKcfBoQRw3CC3sbYfhtd4dMsKUVRjn20pzeETqvtbCwpXzeD2H7tuKcoyrGPCgaEiGF0YmEEAhBwhCLcILb29FYU5ThABQOcfhge11JnWVLeSj/cznuuJaIxDEVRjmFUMMDph9E2htFBxz2vVRGuhaH9MBRFOQ5QwYD2LinpxCXltSrCtRhagt5qYSiKcuyiggHd67jXysII1yWlFoaiKMc+KhjQvh9GZ1lSXquiuxaGxjAURTmGUcGADrKk/PDsl+Dd37Te12tVhG1hqEtKUZRjn4h23DtmMKZ9xz1/M+z+2M594eVQLAx1SSmKchygFgY4FkaItNqGKqgrbb1vKwsjDMHw+4JDpatLSlGUYxgVDAidJeVvsrPq1bYRjFYWRhguqUMJkiuKohyFqGBAiAmUYqDemV68ttS6rFy62w/jUGIeiqIoRyEqGBC6454rGIFmaKwKbvN1s6e3TwVDUZTjAxUMCN0Po7EyuOx1S3XbwuimC0tRFOUoRQUDQqfVeqkrC37ubk9vtTAURTlOUMEAO25UWwvDS4cWRneD3polpSjKsUtEBUNE5ojIJhHZKiK3hdh+o4iUiMgq53WzZ9sNIrLFed0QyXKGdEl58abWdrcfRqugt/bDUBTl2CViHfdEJBq4FzgPKASWishLIaZafcoY8802x2YAtwMFgAGWO8dWRKSwJgAS6ylAGx2tLQl+7m7W06EMVqgoinIUEkkLYzqw1Riz3RjTBDwJXBLmsecDbxljyh2ReAuYE6Fydm5hRMVCrTeG0V0Lw+uS6iULo3g1/P1caKzpnesrinJcEEnBGAzs8SwXOuva8gURWS0iz4pIbjePRUQWiMgyEVlWUlISapeuCdUPw33vOzC0SyomIbyYhGthxCX3Xgyj8FMoXArl23vn+oqiHBdEUjAkxDrTZvllIM8YMxF4G3ikG8falcbcb4wpMMYUZGdnH1pJQ/XDAIjvC32y2ge9o2IhJr57Pb3jknsvS6rBSRFuO8yJoihKN4ikYBQCuZ7lHKDIu4MxpswY4za7HwCmhnvsEaUjl1RCX0jKamNhNFmxiI7vXk/v+OTe64fRIhjlne+nKIrSCZEUjKXASBEZJiJxwDzgJe8OIjLQs3gxsMH5/AYwW0TSRSQdmO2siwwd9cNosTA8MQx/I0THhW9huPvEpxwFFkZZ5/spiqJ0QsSypIwxPhH5JraijwYeNMasE5E7gGXGmJeAb4vIxYAPKAdudI4tF5GfY0UH4A5jTOSax237YbhDnSekQlKmzZIyxo5o62t0LIzY7vX0jktuP5BhT6GCoSjKESCi82EYY14FXm2z7ieezz8EftjBsQ8CD0ayfMGLhRjeHIIWhr8RmmqCVkJ0nHVJhdXT29nnaLAwekuwFEU5LtCe3uAIhjfo3SaGAcHK1rUwYuLC7OntpNLGJfdePwy1MBRFOQKoYECIGIbzOb4vJDmZV65g+JusdRGuheH3Whi91A/DHXlXBUNRlMNABQO6yJJyBeOAffc1WusiJr57Pb3je7EfhmZJKYpyBFDBgI477sX3heR+9nONIxgtFkZc+BaGRENMop32NRA4smXvCmO0H4ZydFBbCo9eGnyWlGMOFQwI0XEvlIXh9CLvtoXhiXlAzwe+m+vtJFBRMdYlZUL2f1SUyFO0CrYvgqKVvV2So5uAv+cblmGiggFOymyItNr4vrayT0j1WBiN3bQwmm0KbnQvCYZrXaTnWQvHO3ugovQk7qRkDZWd73ei89jl8EbI5NFeRwUDQqTVegQDIKmfJ4bR5LEwwnRJuUFy6D3ByBhu3zXwrfQWDU5jRQWjc4o/g5KNvV2KkKhggDUBOwp6g41jtGRJeS2MMIPevemSahGMEfZdA99Kb9FYbd+PB8Eo2wYVO4/8eZsboL7Cvo5CVDAgRD+MthZGdtAl1SIA3bEw4oIuqZ7ui9HWwtDOe0pv0XgcWRgv3AKvfPfIn7dmn313U+GPMk54wTDG4PP7qW7yBJmGngYTroSMYXY52eOSahGAcEerbWotGD3dF0NdUsrRwvHkkqoshIO7j/x5q4rtuwrG0UmjL0B1fRMb9nkmF8oYDl94wFoRYGMYDZXWOvC6mMKdDyPGKxgRtDB2fADPfrl1hkWDc+NlqmAovYxrYRzriRfGQM1+W7mHm3W4+hl4Yn7X+1U7gtFYaV3lRxknvGAkxEYTF2UorurEWkj2pNZ6LYxw+lW4MY+YHgh6b34d1j4LZVuC69zWXN/BttwqGEpvcTTFMAJ+eO93hxaHqK+wqerNtcHv1BWf/BU2vWpjFJ3hCgaE/ztV7u2xydFOeMEAiIkylNb6KK/toDJ3+2LUHAjRr6ILi6Fl/ozY4HKkqHKmDClcGlzXUGk7DcbEQ59M7byn9B4NR1Fa7crHYNEvYO3z3T/W2/Gwel/X+1cWwt7l9nNtF7OCegUj3MD3B7+Hv58X3r6HiQoGECMQQPh4ewet7ySnt3d1MWBap8l2FcT2Nzr9MOKDy5HCvXn3fBpc11Bp+5GAjcWEc4MrSiQ4WoLejdXwn1/Yz4dicdfsD36uDmNet43/Dn6u7aCX+/51UL3C18qyAAAgAElEQVQ/GMOA1oLRmeurrsw2BnsAFQwgSgwx0dF8tK2D1rfrkqostO9uPwyAXR/CxldDHwethxKB1kHv/evh8XlH7gFyb97CZcF1DQeDgpE2JDKBOkUJh0gFvQuXQ+nW8Pf/5D5bccckHlrWoNdKCKcBtuHlYIOxo2FR/nkZvP7f9nzuvm7ge9Nr8PtRULI59LF15ceHYIjIHBHZJCJbReS2ENtvFZH1IrJaRN4RkaGebX4RWeW8Xmp77BEt5ylfpar/KXy0rQsLo3KPffcKwBs/gpe+1XELoKWjX4i02hWPwubXYPnDh/0dMMa2TqJi4cD6loezrKyE+uhku0/aUCsYOjyI4rL2+c4bPEeSlhjGEQ56P31d93pGF62E7JOh38ldu4hC4bUwqrqwMBqrbaNy3GXOsSEEo67cnnPH+1C1F7JH2/X1FbDrI3jmRitwHQ2pUlcGfTK6/TUOhYgJhohEA/cCc4GxwHwRGdtmt5VAgTFmIvAs8FvPtnpjzGTndXGkygnAuT8lZeKFbC+p5aOtIVoccX3sfBahLIyKnTYu0FFLw9vRD1oHvbe8ad8/ue/w023rK+y1hs8EDBStwBhD8f79bK9xOiKmDQVfw7E/+FvAb3vDdkRTHTTWtF63a0l4v3Eg0HpK3sNl3xr45P4jd74jzbt3wuI/9My1GqtsB1l/Y9fB33CpKrKV7L614R9zcJe1tvtkHVpMr2a/fZ7j+3ZtYVTutf28hp1ll0O5pEqdJJW6MqjYAf2carK+At66PTgA6sFd1iL6ywwoXh08vrb0uLAwpgNbjTHbjTFNwJPAJd4djDGLjDF1zuLHQE4Ey9Mp86cPYXhWEt9/djXVDSEqlqTsoGB4BcBl3+rWy8WrYdlD1sJo1Q/DEYyybVC+DU46z97w6xYe3hdwg2VjLrTve5ZSWd9MUqCG0uYEuy7dMeB62i1VUwJP33DkKuK1z8F9Z3ec4fLiLfCkJ4WxYhc8NAdWP931udc8DXePP3J58Msegte+b3+Dow1j7L1Q0wNxreYGe++nDLTLbd1SVUWHZvm67tfqovCDxAd3W8FIyjq0e7LmACT3t9/FG6QOhbs9PQ/iU0PfB6VtXE39Trbv9RU24/GkcyF5gBWMwmXWg7DqX3YfY46bGMZgYI9nudBZ1xFfBl7zLCeIyDIR+VhELo1EAb0kxkXz+ysnUVxZz7efWElDc5sc6IzhwVZMjCdN1sUrGE111kx+5Tu2BRMTQjC2vm3f5/4GskZZKyNcKve2jlNA8MbMPtm+Cj9lb2klA6WcnY0pGGPsQwL2xutJNr4M61+AHe8dmfMd2ACYYMusLXtXWIvCbcW637d0U9fn3r8Omuu6/xtV7Gzd6nNx/5ddH3bvfIdK9b7wM/FqDoCv3gZbD9dNaUx7q86L645KzbXvXsGoKoa7J9h7pLu42Ufg3Bdd0FBpX6m5wazB7n73mv221Z8yIAzBcMQ4ZYCNhXrdWS5lW2z90NdpL6fmQlyKvQfrKyB9mH12K3YFU+Y3vhqcusD4gzODRphICoaEWBfynxGRa4EC4Hee1UOMMQXA1cDdIjKig2MXOMKyrKTk8Fpx+UPS+fml43l3cwnX/eMT9lV6zObJV9uHC4L9MABik6yrx1tZLPplsPXrBr1j2mRVbXkTMkdC5giYeiPsXWaD4F4W3w3v/Nx+fv1H8MhF9iZZ+FV4+ILWriU3uyJlIOQUQOFSqrYvJUGaWdJ8EmW1TUHBqNhpK5We6nW+6yP73p1c8XULO/YPu+cJZWH4Gm0LMtAcdFu5D23Ztq6v61qRlXvDLyvY/+fp69qvr3LOs3Nx9853KDTVwZ8K4NMwXWCuKPobD3/sorXPwf+N7tgyczOkUp1K0SsYpZttn6a2jaBw2LscUgbZz/vXdb3/QacN61oYvgZoqu3eNVtZGF1YZ9We5zKpX+iYSekWO9bb8LOD+yam2+HgwVonbsKKa41U7rbuTjfL6ziwMAqBXM9yDtCuBhCRc4H/AS42xrREhI0xRc77duBdYEqoixhj7jfGFBhjCrKzsw+70NecMpQ/zpvCmr2VnHfXe/z9g+3UNvpgzEXB/hjefhgDJ8GgyfbPA3sDf/wXKwK5pzr7xwX7Yfib7cO5430Ydb5dN3GeFaFP/gYvfRs++D/78L//O+tf3r8Olv3DHrPoV7DzA3ujL/lzsOAtN+YAyJkO9RWkbX4WgOWBUewqq4W4JPsdDu6Gf33BBtMijTGw02ldl+8I75i6clu2JfeG3t6ZYJTvoKVd4vZHcYUnnOu7glHVTcE4sM62ANv65l0h7wnB2LcamqrDa2mDLa9LqJZvdyhcBk01UObJVnp8Hvz7e/azKxCuYDR6BMN1kZaEYQF6CfhtIPjkC2wm4IH1NqNo26KOj3ETV9KG2hgGdD+OUXPAPkd9HcHorPNudbEtW1wfx8IIFcPYDFkjYeRsO/BpxnBITIUS539Mz7Pu5Kq99jfKHAmI7QjoDiZ6HAjGUmCkiAwTkThgHtAq20lEpgD3YcXigGd9uojEO5+zgNOBNs3vyHHxpEG8/l9nMSk3jV/8ewOn/vodvrdwIzuHXA5AaQN8sMOa2KV9x8KACTZYVVduK/zk/nDeHTDxi/aEXovE3wjrX7SWx4Qr7LqkTDj5QljxiH0t+rVtJTbVWHPziXlWIJKy4f3fWnN11BxY+o/gDVNdbG+amHjInQ7AScUvsyPQnxLS2FHqhIrShtgW/4737cMVKq0wELBCdSQGKqzYGUz3LQ+jhQ/BoZ1dEfZiTLDiDykYzjUkCgqd/ihuK7B8e9c981ssjMLwygpW3Ct2AcbeBy7+ZtuijO9rH37Xf73sodDf7XDZu8K+V4YZozq4M/i5K9eKl8ZquPcU+Oyp4Dr3d3fF3Ndk3a7LH7a/v2thpIVwSbUIRjeH9C7ZZJ+RnAIbKN65GJ79ErweImPqs6fgvd8Gr5WWG3TjeOMYxsDDF8LCr4V2sQX8VmBcCyPQbFv5/mZ4//ftYzPVxcG4jXeaBBd/s72Ps0bC2Evg1o1WiBLTbbAcghZGwGcbpENOtc/45tc9FsYxniVljPEB3wTeADYATxtj1onIHSLiZj39DkgGnmmTPjsGWCYinwGLgDuNMT0mGAB5WUk8dvMpLLzlNM4b25831u3jiysn8aL/NM55/CA/e8tWKLev6MNfNibZgx6aC/vX8nDaN3lydSWVwy/EH5PE0tJYHvrYtlj9zU12XJnMkTBwcvCCM75pfZVzfwcYeOdn1pc5ao69yXOmwfm/svvmXw/n3G4fluUP2XVVnhszazTE9yXWNLElfhxRAjtLHbM7bWjQD2r8Vrzasu8zePunwcDa4eC6owYXdO2SKtsGfp9tKQLsX9vev1xbalvRENpicFu4Iz7XOiAK1qXYWYDX3xysODuyMA7uad25Cpzf07S+PjhCZWCsc7vvWmxdXa98B965o+NyHCpFjmCEm9RQsYsWz3F1GBZGXbkV3E8fsJX7Bk/7z/3e7n9cstFWpoFm27BpiWE4btFWguFYOpV7wh9qA4Lfd/BUKxilm238qWRD62H8A377PL33W2utxyTYxpfrMfBaGDX7rQX/2RPw4Pmt0+CbG+x2EwjGMMDeM7s+hP/8vP3zVL0vuF9yf/u9vVZo+Q4rBFmj7Jw8bp+vxHT73ifTTrPgupMDPisuOdPgwMagi6uHLIyYSJ7cGPMq8GqbdT/xfD63g+M+AiZEsmzhMmVIOlOGpNPkC/DhtlI+2T6V76UnMmFwKjU1IxmxeyD//HAdF0sWzRWNvCxXc/fWYQS2rOE2IJPfU7kiCR+buT5eeGvR28yJ+pSFaTdRtWQXl+cPJkqEv6xL4rna/+NLjXncPP6LRK1+AiZ80fo1N78O026G8V+wD8TYS+wNlXcmrPgnnP7d1i2ZqCj7EG1fxL7UyeTE9mFHmSsYzo03cJK9cdc+D9O+3PpLux2EXB+qizG2FXXy56H/uI5/tFd/YFtFM26xD1JiBoyeax+oxhqIT25/TFUR3DsdZv8iWPnUldnv1XdQcD+3QsoYYVtmxrSe/Kpsq3U1nHSebeFW7rUVfHScterKtrU+X9syuBV/RzGMZ2+yFc6NrwTXeV0p3jiJKz6jL4ANr8C6F4IV87b/OB2uOmgZNlRaKyk+JfT2ULgB4MpCW0l6px328sI3rIvj4C77P+5f27WFUVduA9M504KxoT2f2t8/4Au6t9zv7+7Tb6x1p876H7vckYUhUbYiLtkMOVPD+77Fq226e8YI6O+kog6cDMWrYPcS66oCKwBuA2Dt8/YZEAlWsl5L2k1syb/BWvs7F8NJ59h1j1wUvP+S+wefpbKtQbfngTZWUvU+yDvDOcYzJp37O7iNt8yRrY9LSLPv6Xn2PW1ocFvmSHtf+OqDyTbHg2AcT8TFRDFrdD9mje7nWfs5bh0D1502nEeXTOCjbWUkxkbzzqXj2VlWy7q9lYwfnMrI/ilECfj/nMKc5k8JEMWzzafy4UvruP2lYKDu5AEp/OrVjSyMO5W74j/jmaJpTMwcyaW3fAzZJ2MAmXpj8PL518PzX7Et1+pi6xpzMDnTkO2LqOk3jbyaJBvDgGBq7bjLrZvr3Ttthdp3YPC8bjZR245Cuz+24++Ub4PL/hb6h/L77IOW1A9O+Zr1J+edAZkn2e3l22HgxPbHbX/XVjxb3nQ6OyY6D8Ta0IIx4nOw9AH7sCd7Yldl2+y1cqbZ5b3L7EM7eKqtRMq3w7AzQ5fddUMl9YOqEC6pgN+6kkzAim2sk65cstH6nuNTWrvd3EokLRfyr4Mlf7Hikphu41gbXrKxLu9vJ1FW8B+fB7GJcF0XYx0FAjbmNXSG/W5ucLS6OBgv8NLcAKufgtg+NqY19DQntbYLC6NopbVotzvxgcnXWAu0Yoctg3GyCt3/Z59TmZ/7U3j8SutvB1vRRsW07rznWtB7PrHWgVcw6iusSy+U+O1bDf3H299r5GwY/XmbdfinqdayPelc+5999qQzt43Y2EmqddkGXVKeQPR+x1U484f2uK1vW8GoLHRcnE7jJGWAFcPoeCvUruiUeOJHgYDTkHMsDLcDcO2BoGDs+dT+HtmjWn8318JId6ZYSM1xrm2sheE2uvZ8YssQF6IRFgFUMI4A2Snx/L/Zo/l/nnXDspLaiAtwwwtQVUhUeh7/GjiJ1YUHWbSxhCiBU0dkMi0vg/c2l/CfDfu5fd9odhfW8eD6Vbw/ZTAb9y1mR2kto/onc8NpeVw2ZTAy5iIbUHv5v+wD77Z4gIrxN/KrdyoZN+hkhpXVsWJXBcYYZOjp0G+ctV6aauHdX9t0xlO/Hiyn22Ku2GEfWPfmdXukb33HPgxRITyaZVutEFXuhjXPWHfQ6LnB+Tg6EwywD3pMAoyeYzOl9q+BUbOD+1XssJXq8LOtYFTsaCMYW21F0X+cfRD3LrcP7bhLrIuqsziKKxhDToFNr7f/jgd32e8GtgIdOsN+PrDRtnL7ZIS2MFIGQcGX4aM/2wrl7P+2WUVrnwsKhjHwj3Ot6J/7MytuIu2tEH+zdZO4FUbhUivibtr22Evho3tsJRxKMPatsW6ixkr7Sh9qK/HqYvudfE32+7fFtRiufsbum1NgBWPPp8HWcP8JQcEodirzvDPs/7DjA7s+PsXes66F4Wuywjr5amvRegP2taVwzxRbQV50jxXQtCE2gSQQsN9l8tV237QhMP8J+3lwAWx/D3bNse5NE4BJ820cZd3C4HMSl2wr27o2FkbqENuAyjsDtrwFc35tLUKAa5+zv+3gAntvDJxk7yvXlXZgo32unl9gvQIBXzCLy+2At/lNe7+fcattNOSd2d6SbBGMPPseE289CLUH7Lq4pGB5k/u3trIjiI4l1ZPkTLXupIGTAJiYk8Z/nTuSb50zkml5tlI4e1Q2P7tkPE9/dQYf3vY5bjwtj+dX7qWh2c+VBTk0+w23Pv0ZF9yzmJ+/sYM34mbjL9/J8vTP82LcBewpt8Ht3Y1JPOs/m5yMJPKykqhp9PHdp1axurE/3PIRpA62rZoBE2zF5aV0c/CGdd1SdeX2YXNv2v0d9Kz1BnPf+l9buY88PzgZ1a6P7FAq3oC1MfYBSupnK+SGg5B7ijXD2/bgLd9uYztZTovMe57GaiucmSNs67/fWNj6H1tBpubaB82t0D68B/56BjTXB493M2hyT7HH1B6wZfv0AVs+r7th90fBzyUb7XAOGSNaC0ZVka2Q+mTY7z/SEb4xF1sLb8cHwUD4jvdthb3mOVtJYWxFt/mN1ue77yz464xghbv5NVshxzjWzliny9LB3VZYmupohZs55v6/aUOd/gT7ravq+ZsJSfFn9vcbNRum3mD7+sT3tS1c14U48lyoL7f3yr41tmEQlwSDpthkj9g+trL3CkblHvtd04fZ/9Tr3lv+sK3kS7fA306HP+XDaz+w2yp2WItnQAjP9dAZtqFRtMImk2SMgOlfCf7+butepH3nvX1rgu7WkedZl1H5DisYKQOtZVtwU7AhkVNgXWClm6wAVRfZ52TjKzZuAh4Lw2nYvHenjWG991t7P465qP13SGzjkgIr7ul59jdMGWhT+o2/x9xRoBbGUU10lPDTi8dx3Yyh5GUmER0lBAKGZ5bv4ellhTzy0U7eTbuKpwdcySfFhpoXdxIdtYvvnjsSv5NgkePEW5btqmDRphI+2FLKm989i5W7DyIC54y73N7YFTtt5Z4y0N7E+dfDsgdtJTZiFqx6HPyN1M35A32emWdN9VCWwr7PbGvXDa4POc1mgYFtCX3qdFCsLIRrn7durug4W9Gf/2t488f2Ieg3xlYGrjCVbLbpyruW2Bant0+Ji9sKdt1fg6ZY9xjYhzZzhK2Qakrgvd/YCmfp322SwKZ/29Zgn8zg8Qd32z41Kx6FAROD4wGl5tpyg3XxVOyw8aXYBFi1zwpXfErQHeG2/s67w1Zm/cfZ7/j+b60Lbso1NitOou0cC4t+YTPh4pNtuSbPt5beg+fbyri5zvb7uPReawkNmQGzfmRb+25lV7YN7sm3rrWMEXDz21a4CpfaDmITr4TFd9lKKGWAPY+bTFCxK+i6bPltV7U0dADrIsopgN2f2OXEdNvqBntvNNcG9x96ur2u24r2CoYboE8fav/z7e9aq0PEBsuHz4KL/2R/p+2LYPkjcNq3gv/1gBD34LCzrJvu7P+2v4tL38HW/z/09OA675D/zfX2nnWTFEbOhtdvsxb4tkU2JtK2JT94qr0vwYrT6ieD6eCuS9eNLSb3A8TeP9Gx8O6v7LIba/GS6FiVbkMLbKJLs9MAELH3877VPZYhBSoYxwQjsoP+yago4appQ7hq2hD8AUN0lL2BAwHD1pIa7nlnC79/0watM5LiyMtMIjEumnuvzmfjviou+tNirvjbEnY4WVNfHD6C3wFlf5lDZnMxK4fexJSAjwd2ZjM/KZekopU0VOwn8f3fUTf4dAqeEt7qM5JBW9/mH1yKr66KM9PLGFcwk+V7Kolf8SG5KSPpO3IWUrbFBshdMkbYQPa4y+0QHH8/x7qMnPnU791/MldnTCK9bAVkj7EBzI3/tqORvvYD+wAaP0xy/Pspg2wF0lBpH9YXv2lFaagTZBw02SMYg2zrcPPr8PfP2QdvwAQ7iY6vPjiVbr8xtmIBW1nsXW7Lsm+1rVz6DrY+7bULrevh7Z9ZS6D/uGBlsvVtK1ZVbQL2/U4ODvswYKKtSDa/bmMqm161mXIrH7OV6Ki51gpc9bityNY8a9ff+Ko9/+K77PaSDZD/KxuLGHqaPXdyf3ue6iKYfC2seswK49k/sO6TnAI45atWhHKm2/O5YgE20OsVjPoKK8z517e+MfPOtI2Nmv32v810+ta6FahXMD6824kjYMWldLNNgGhJcx1i3aRrnobPHreWWXURXHS3tQimfdlWrFvesi3zlIHWsuo3pv0DM+xs+Mqi1lmIYCvWb7XpHJiUFYw/HNjg/Jfj7XLmCBiUbzMGwd4/bRnsibdM/KIVjAPrW49T5VoYsYlw1WP2vixcavsa5Z4S3O5l5Hkw5ze2MeAydEbrfTJPCt6XPYQKxjGMKxZghWRU/xT+NH8K86YNISrK9lxPiA0GC08e0JfvnDuK372xiasKchmWncR9721jpRnFuObtlEgGE3Y+AgLvlafTrzmX8za8yYZ1FzApqprvVF1Nky/A8zXj+EbDi6Rv/xanRG0kR0opeyeXfzTfwM/9W3itZiqrto7ml6lDWZMyk8btZUzMSePDod/BP6CGaWfOJePABkzxZ6wb8RVGNm1kb2Ujv/u4nj3R+VzXp5E3lxyExrO5Oe5+kh+9GGmqgcvug7GXUOuPYfnmEs783I+RVf+yLqMlf7Yj9d7476BFM8jT17PvQMhZYCuoJX+2Fem0L8MDs6x7JSnbZtOk5gZ9/3uXWxfiGbfC/WfbFu6Ic+xDvPxh+HWOrWCmfcUKlpss8MyN1j0RE28rr1CI2I6ba56FN//XVn7TF1h33IpH7SCS2aNtRb9uoXUbZo+xopBTYFvY7/3GnmvUnNbnThtiK6SkbLjoj7ZC/+Q+mHiVjS2d8lVbSV10t90/2amw0vOsdbTzA2v1uLhuxrYV8Klft6607Yts3Mh1nxSttNaYW/EOOcVarwmOYJzyNTtd6VPXWCGXaPuemmutlP/80pZj4GSb7eaSMsC6lj76k7VSsse0H6LH/W0H54f+3duSlG1djTsXW5GF1m6uG1+x7ssd79nv2Jb0PFthNzfAsJnW7dZcBzNvs0LTVNNaENyx3lIGwZTrbKA+FLGJcOrXOi+7awmrYCiHiohwxsiOx5W5ZeYIZo/tz0n9khERvnb2CKiZDP4msvcuh6dtK/KRH1zLk++OZ/tndzC1/lMeCFzEmyXpPHjjVJ5dksJD2xq5KfYtTHoeL8Rfx7i9T/OHqN8QL82MnHQaP/ksm+fMnTT/azewm+gowR8wQALywSL6RX2TxEANO9cNJDH2XOqb/cyfPoSxg77NDz69lPWLthITJXwc+CpPxP+CHYkT+dIb/bimspjnVhSycV813/pcARfMvYiXlqxjUsWbbPdl8fLCJs4YuYG54wcwLO0kUiSGKONnRXksk1MgevYvYPhM9vadxLrSAHGnPUr28AmMSWki6r7TbQWQmE4gJhEkiqg5d9oK1WkxvlOeweItefxk2leQhFRK+p3KworhXFrro1+/sXDBXbbyf+t/rTXlsTBqG32U1TQxJLOPXTFqrhWe9S/AWT/ApOYgU66z8yeMOt+69QZOslZMzT743I9tZRgTD1c/ZS2g6n3Blr2LKxgTroToGDj92zYl9GGnssopaL2/W6GNmmPdaDs+sJbXmmesgLmuJK9LCmylNu9xO4/D2EvscvbJ1vVy2X1Biysh1QqBG/QddT5c8md44RZa4hfRTlU064fw2BdsZXjNs+0TK2b92L4v+UtLB9XDImWAtWQevgAQ6wJL97iB4pJsmWZ1MHy6iG1ENBy03yFrlHXfnXyhM6bZ4uAoD16iouxvcDi4gtFD40gBiDmO5kYoKCgwy5Ydwng0iiUQgL+cal0g3/UEr8u2sbU5iz0HG5l1cj+a/QH2VTaQG1sFiemY6Dhe/HAln19yLXG1e+FLb7CS0Tz28W5OG5FJXEwUy3dVcN7Y/mQkxfHmuv00+PwM6JvApNw0/rJoKxV1TTz6pVNIjLMWUU2jj4SYKB7/dDcLX3qBvVGDyO4/kHVFVaTExzBtWAb/2XiAKIGY6CiiBDL6xJGb0YfluyrwBex9/VLc/zBQypnW+FfS+sQyIjuZfZUN7D1Y3+qrpyTEcFriHuqTBrO/OYkLyv7B5kAuy1NmUdvo4w9xf+WcpkV8v3kBz/hncsXUHALG8PJnRTT7Df37xvO5k/vz+tpiTjspi+/lbGTYf74Oc3/LhiHz+dcnu3hhZRE1jT5mjc5mxohM+kgT8989G0kZRO2X3+faR1aT1ieOe+ZNIbVPLJX1zez59GXGL7oJgAM3fQzpw0iKj6Guyc9db23mQFUDd35hIqmJsTT6/KQkxNqW7eI/8Nikxxg95XSmDU2H5262fRFyp1tfuCdN1bf3M2IeOIv6a14msWITvGqH8/ANOYOY9FybcZScTcW1b5OaGEuUY9kaY5C2Pv2mWhuAb5sGW1Ni13n97RW7rEslNde6aexJbeZQR64al6piK2Sh+vR0QiBgWsrfUq7ti2y5Bk4JWqfdwe/DzsQZa8d+K15ls6kaa5yBDjsbc/UwKFxu3auf/721vA4REVnujNvX9b4qGEorSjY7WUqH0Ho7sNEGymf/IjjW1hFgybYyBqclkpuRyLubS8jLTCI3PZGfvLSO2CjhO+eOIj0peL3y2iY+3l7G5v3VXG7epp9/P28P+ir/2XiAooP19EtJYHJuGlOHppOSEMOqPQdZufsg5XVNHKyzI72ec3J/fIEA64uqSEmIJXPHy3yn8k4Wn/M8/zk4kAc/3EFyfAyX5w/mnDH9+fELa9hX2cDZo7JZsq2M2iY/06K3sIkhVPnjiYuJ4sKJAxmS0YeHP9rJwTo78OPMqJU09hlMc+ZoVu45SJRAVnI8WcnxbNxXRbM/wOMJvyUx2s9ltT9q9bvERAnRUULfxFia/QHqGv1cN2MoKXV7qFr3Jg82ziIxNoZbzxvFwx/tJDEumisLckiKj2H5zgq2HKjh++eP5t+ri3ln2VpIzmZubjPf3fl1/t40m0eiL+d/LxyHMYbnVxSydNdBzhyZxcWTBvHr1zYyMDWBm88cxgUTBhEXE0V9k58F/1zGwbpmzhiZxXfPHUVcTNBCKK1pZNnOCmaMyCQ1MZbSmkZuf2kddY0+/nrtVJbtrGDjviq+dPow1hdXsb6oii8W5LQXJToQqy5YurOcmx9ZxoKzhvONWSd169iOMMbwk7toTUMAAA1rSURBVBfX0ewPcOcXWgfg1xVVsqawkisLcluL1JHC1wgvfwfO+l57K7MbqGAoypHGGOtiyJlKIGBYvruC8YNSWyyi2kYf9c1+spLjqaht4oOtpWzaV0XAwMDUBC6aOKhF1PwBQ0Ozn9omHxuKq/nVvzewaX81v7xsPKP6p3DPO1uIjhJG9ktm6tB0Xv1sDzUNzZwxehDxsVHUNPho9AW4YOJA6pv8/OTFtQxO70NstLBw5V7iY6I4Z0x/rjt1KD96fg3bnf47cTFRrN1rO8z1TYghtU8se8qtpTV/ei57yuvZVV7LsMwkpuVl8MGWUj7daYfYyMvsw1mjsnni0900+w0TBqdS1+RjW0kt/fvGc8NpeawvquLfa4qZOiSdZbsq+MGc0Vw4YRB3vbWJXeV1rCmsxBcwpMTHMHZQX9YXV9HYHKDJH2B6XgYrdlvLcObobD7ZXk59s59fXTaBy6YMZtP+apLjYxiUlsCG4mq+89RKBvRN4PaLxjF+cGqrv2pdUSX/XLKLyblppCTE8smOMgakJnD/+9upb/LT6Atww4yhnDI8k7LaJg7WNpGSEENWSjwDUxPITIpn6c5ydpXVcf2MofTrm9DhbfH00j384Dnb2/qt757FyP7Wfdfo8zP7D++zq6yOM0dm8T8XjGF0/5Rui1yTL0BstCAi1DT68PsNqX2CLq6tB6oZmplEbPSh95BQwVCUY4hGn5/tJbWMGdj3sM+1r7KBvokx9ImzMYH9VQ28u+kAl04ZTFx0FAeqGzEGMpPjaPQF+MmLa0lNjOUnF45tV5n5/AEWbSohNyOxpbJbsbuCFbsquH5GHjFRwntbSvjHBztY7MxU+f3zR/ONWSfxtX8u593NB8hMiqeyvpmJOalMGJzKqSMyeWHlXvaU15GXlcRXzxrB2xv287s3NjFlSBqnjcjk3kXbGD+4L2mJcXy6o5yE2CiqGnwt5RKBwWmJ1Df5Ka9rYv70IQxOS+Tj7WUkxEbz7iY7wF+z39ZtCbFRNDQHyEyK45mvzeCv727jmeXhDS6ZEh/DTafncVL/FO57bxu1jT6m5WVw7tj+7Kts4Devb2TMwL6s3VvJpZMHExUF2w7UcvLAFB5dsovrZwzlqaV7aPQFGJ6dxOfHD+SqabnkZvRpucbWA9Us2lhCUnwMZ47MIjejDx9uLeUX/97A5v3VTB2Szp+vnsK8+z+mqqGZp786g+HZySzadICbHlrKnHEDuPea/FZJMN1BBUNRlB5lQ3EVG4qr7AgEIhQdrOfcu94jJkp4/CuntrMCvBhjWLy1lPwh6STFx7BydwWjB6TQ5AvwpYeXMjAtkQsnDKTJH2B3WR3N/gA3nzUcY+CPb2/hkSU78QcMJw9IodkfYPzgVG6/aBx7yuto9AXIH5JGRV0zSfHRLUJa1dDM7rI6MpLiyEqOp7qhmZKaRoorGzhQ1cBJ/VLISIrjl/9ezzsbD2CMHb3hpH7JfLqjnMp661LMH5LGvdfkc/dbW3hqme34mRwfQ02jj3PH9OPvN0yjpLqRN9bt49U1xXy8vYzoKOGKqbmcNiKT51YU8u6m1nNkTMxJZV1RFUMz+3D6iCwe+2QXSXExNDT7SUmIISE2mt9eMZEfPr+G6gYflfXNzJuWy68vn9BtCwZUMHq7GIqiAGsKK0lOiGFYVlJEr+MmMAxOS4zI+Ysr69lYXM0ZI7OIjY6i2R9g6Y5y+sTHMDnX9sjesr+aK+9bwi0zT+Ky/MH8c8ku5k3PZWBq6zIVHaznT//ZwvMr9tLoC5CSEMMtM0/i0imDqG3089b6/bz0WRGj+ifzy8smkBwfw8Mf7uCnL6/n55eMY+rQDG586FMOVNtRdJ9acCofbCnlw22lPPblU0iK737iqwqGoihKD9MuA6sTGpr9rC+uYlhmUquEjY6oqG1q2a++yc+/PtlFTJRw4+nDMMbQ6Au06nPVHbojGNoPQ1EU5QjQnUyohNho8oekh72/V1QS46K5+czhLcsicshi0V108EFFURQlLCIqGCIyR0Q2ichWEbktxPZ4EXnK2f6JiOR5tv3QWb9JRM6PZDkVRVGUromYYIhINHAvMBcYC8wXkbFtdvsyUGGMOQn4A/Ab59ix2DnAxwFzgL8451MURVF6iUhaGNOBrcaY7caYJuBJ4JI2+1wCOMOJ8ixwjti8sEuAJ40xjcaYHcBW53yKoihKLxFJwfj/7d1vjB1VGcfx7y9bIFUQAq2kkT9ttZpgotA0hqDwQo3RRvFvBEJigyREAhFiNJA0McT4phqNaSCSEhqVoEGjxH2jllQDIUpxt+7SrkUKpMbK0m4xUo2E0Prw4pwbp9c73bnbvWdG9/dJbu7ss3N3n33m7Jw7M3fOeQvwl8rXB3Ns4DoRcQx4GTiv4WsBkHSTpAlJE3Nzc4NWMTOzRTDKDmPQRwb6P8Nbt06T16ZgxLaI2BARG1auXDloFTMzWwSj7DAOAhdWvr4AeKFuHUnLgLOBvzV8rZmZFTTKDuP3wDpJaySdTrqIPd63zjiwKS9/Bvh1pDsJx4Fr86eo1gDrgCdHmKuZmc1jZDfuRcQxSbcCvwLGgO0RMSPpa8BERIwD9wMPSHqWdGRxbX7tjKQfA38EjgG3RMTx+X7n5OTkEUl/XmDKK4AjC3ztKDmv4XU1N+c1HOc1vIXkdvH8qyT/V0ODnApJE01vjy/JeQ2vq7k5r+E4r+GNOjff6W1mZo24wzAzs0bcYfzHtrYTqOG8htfV3JzXcJzX8Eaam69hmJlZIz7CMDOzRtxhmJlZI0u+w5hvCPaCeVwo6TeS9kmakXRbjt8l6a+SpvJjY0v5HZC0J+cwkWPnSnpE0v783HxGmMXJ6R2VukxJOirp9jZqJmm7pMOS9lZiA+ujZGtuc09JWt9Cbt+U9HT+/Q9LOifHV0t6pVK7ewvnVbvtSk15UJPXQ5WcDkiayvGS9arbR5RrZxGxZB+kGwqfA9YCpwPTwCUt5bIKWJ+XzwKeIQ0Lfxfw5Q7U6gCwoi/2DeDOvHwnsKXlbfki6Sak4jUDrgLWA3vnqw+wEfgFacy0y4FdLeT2IWBZXt5SyW11db0W8hq47fL/wjRwBrAm/9+Olcqr7/vfAr7aQr3q9hHF2tlSP8JoMgR7ERExGxG78/I/gH3UjNDbIdXh6b8PfKLFXD4APBcRC73T/5RExGOk0Qqq6urzceAHkTwBnCNpVcncImJHpBGiAZ4gjddWVE3N6hSb8uBkeUkS8FngR6P43Sdzkn1EsXa21DuMxsOol6Q08+BlwK4cujUfUm4vfdqnIoAdkiYl3ZRj50fELKTGDLy5pdwgDStT/SfuQs3q6tO1dvd50jvRnjWS/iDpUUlXtpDPoG3XlZpdCRyKiP2VWPF69e0jirWzpd5hNB5GvRRJZwI/BW6PiKPAd4G3ApcCs6TD4Ta8NyLWk2ZQvEXSVS3l8V+UBre8GvhJDnWlZnU60+4kbSaN1/ZgDs0CF0XEZcCXgB9KelPBlOq2XVdqdh0nvjEpXq8B+4jaVQfETqlmS73D6NQw6pJOIzWEByPiZwARcSgijkfEv4H7aGnmwYh4IT8fBh7OeRzqHeLm58Nt5EbqxHZHxKGcYydqRn19OtHuJG0CPgpcH/mkdz7l81JeniRdK3h7qZxOsu1ar5nSFAyfAh7qxUrXa9A+goLtbKl3GE2GYC8inxu9H9gXEd+uxKvnHD8J7O1/bYHc3ijprN4y6YLpXk4cnn4T8PPSuWUnvOvrQs2yuvqMA5/Ln2K5HHi5d0qhFEkfBu4Aro6If1XiKyWN5eW1pKkFni+YV92268KUBx8Eno6Ig71AyXrV7SMo2c5KXN3v8oP0SYJnSO8MNreYx/tIh4tPAVP5sRF4ANiT4+PAqhZyW0v6hMo0MNOrE2k63Z3A/vx8bgu5vQF4CTi7EiteM1KHNQu8Rnpnd2NdfUinCu7JbW4PsKGF3J4lnd/utbV787qfztt4GtgNfKxwXrXbDtica/Yn4CMl88rx7wFf6Fu3ZL3q9hHF2pmHBjEzs0aW+ikpMzNryB2GmZk14g7DzMwacYdhZmaNuMMwM7NG3GGYDUHScZ04Qu6ijXCcRz5t654Rs3ktazsBs/8xr0TEpW0nYdYGH2GYLYI8R8IWSU/mx9ty/GJJO/NgejslXZTj5yvNQzGdH1fkHzUm6b4838EOSctb+6PM+rjDMBvO8r5TUtdUvnc0It4D3A18J8fuJg0x/S7SAH9bc3wr8GhEvJs098JMjq8D7omIdwJ/J91JbNYJvtPbbAiS/hkRZw6IHwDeHxHP5wHiXoyI8yQdIQ1v8VqOz0bECklzwAUR8WrlZ6wGHomIdfnrO4DTIuLro//LzObnIwyzxRM1y3XrDPJqZfk4vs5oHeIOw2zxXFN5/l1e/i1pFGSA64HH8/JO4GYASWOF55wwWxC/ezEbznJJU5WvfxkRvY/WniFpF+mN2HU59kVgu6SvAHPADTl+G7BN0o2kI4mbSSOkmnWWr2GYLYJ8DWNDRBxpOxezUfEpKTMza8RHGGZm1oiPMMzMrBF3GGZm1og7DDMza8QdhpmZNeIOw8zMGnkdm3M+Q/fBXkUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: \n",
      "Threshold:  0.039696969696969696\n",
      "Precision: \t 0.9701195219123506\n",
      "Recall: \t 0.9643564356435643\n",
      "F2: \t\t 0.965503568596352\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, fbeta_score\n",
    "\n",
    "def best_threshold(X_val, y_val):\n",
    "    predictions = model.predict(X_val)\n",
    "    \n",
    "    best_f2 = 0\n",
    "    for thresh in np.linspace(0.01, 0.99, 100):\n",
    "        y_val_predict = (predictions > thresh).astype(np.uint8)\n",
    "        f2 = fbeta_score(y_val, y_val_predict, beta=2)\n",
    "        if f2 > best_f2:\n",
    "            best_f2 = f2\n",
    "            best_thresh = thresh\n",
    "    return best_thresh\n",
    "\n",
    "threshold = best_threshold(X_val, y_val)\n",
    "y_val_predict = (model.predict(X_val) > threshold).astype(np.uint8)  \n",
    "\n",
    "print(\"Validation: \")\n",
    "print(\"Threshold: \", threshold)\n",
    "print(\"Precision: \\t\", precision_score(y_val, y_val_predict))\n",
    "print(\"Recall: \\t\", recall_score(y_val, y_val_predict))\n",
    "print(\"F2: \\t\\t\", fbeta_score(y_val, y_val_predict, beta=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"Models/mode_\" + str(mode) + \"/conv1D.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model_mode0.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: \n",
      "Threshold:  0.039696969696969696\n",
      "Precision: \t 0.9660194174757282\n",
      "Recall: \t 0.9719169719169719\n",
      "F2: \t\t 0.9707317073170731\n"
     ]
    }
   ],
   "source": [
    "# TEST\n",
    "y_test_predict = (model.predict(X_test) > threshold).astype(np.uint8) \n",
    "print(\"TEST: \")\n",
    "print(\"Threshold: \", threshold)\n",
    "print(\"Precision: \\t\", precision_score(y_test, y_test_predict))\n",
    "print(\"Recall: \\t\", recall_score(y_test, y_test_predict))\n",
    "print(\"F2: \\t\\t\", fbeta_score(y_test, y_test_predict, beta=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
